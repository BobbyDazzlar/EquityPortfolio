{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_years(y):# calculates the number of years of the dataset\n",
    "    p = y.index[0]  # date of first row in the dataset (datetime format)\n",
    "    q = y.index[len(y) - 1]  # date of last row in the dataset  (datetime format)\n",
    "    return ((q - p).days + 1) / 365  # the difference give the number of total days (not trading days) over the total number of years in the dataset\n",
    "def number_of_years(y):  # calculates the number of years of the dataset\n",
    "    p = y.index[0]  # date of first row in the dataset (datetime format)\n",
    "    q = y.index[len(y) - 1]  # date of last row in the dataset  (datetime format)\n",
    "    return ((q - p).days + 1) / 365  # the difference give the number of total days (not trading days) over the total number of years in the dataset\n",
    "def BALANCE(weights):\n",
    "  #Making sure the total sum of the weights eual to 1\n",
    "    weights = [w/sum(weights) for w in weights] \n",
    "  # Making sure all weights represent proportions that add up to 1\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('n50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pso_sharpe=pd.DataFrame(columns=['Date', 'Returns', 'Risk','Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHARPE(weights, mean_daily_returns, cov_matrix):\n",
    "    weights = [w / sum(weights) for w in weights]  # Making sure all weights represent proportions that add up to 1\n",
    "    weights = np.matrix(weights)\n",
    "    port_return = np.round(np.sum(weights * mean_daily_returns.T) * trading_days, 2) / (\n",
    "        no_of_years)  # 1259 trading days over 5 year period\n",
    "    port_std_dev = np.round(np.sqrt(weights * cov_matrix * weights.T) * np.sqrt(trading_days), 2) / np.sqrt(no_of_years)\n",
    "    port_std_dev = float(port_std_dev)\n",
    "    sharpe_ratio = (port_return - 0.0358) / port_std_dev  # 2.57 represents annual return of risk free security - 5-year US Treasury\n",
    "\n",
    "    return sharpe_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_OPTIMIZER(swarm_size, iterations):\n",
    "    mean_daily_returns = []  # IT WOULD CONTAIN THE AVG RETURS OF THE ASSETS\n",
    "    all_return_input = []  # cov_input # IT WOULD CONTAIN THE [DAILY RETURNS] OF THE ASSETS\n",
    "    neg_return = []\n",
    "\n",
    "    for stock in stock_names:\n",
    "        indv_stock = data[data.Name == stock]\n",
    "        avg_return = indv_stock.Daily_returns.mean()\n",
    "        mean_daily_returns.append(avg_return)\n",
    "        all_return_input.append(indv_stock.Daily_returns.tolist())\n",
    "\n",
    "    neg_return = all_return_input[:]\n",
    "    mean_daily_returns = np.matrix(mean_daily_returns)  # CONVERTING 1D LIST(mean_daily_returns)INTO A MATRIX\n",
    "    all_return_input = np.matrix(all_return_input)  # CONVERTING A 2D LIST(cov_input)INTO A MATRIX\n",
    "    cov_matrix = np.cov(all_return_input)\n",
    "\n",
    "    for i in range(len(neg_return)):\n",
    "        for j in range(len(neg_return[i])):\n",
    "            if neg_return[i][j] > 0:\n",
    "                neg_return[i][j] = 0\n",
    "    sortino_input = np.matrix(neg_return)\n",
    "    cov_matrix_neg = np.cov(sortino_input)\n",
    "\n",
    "    ''' w,c1,c2 ARE PARAMETERS WHICH WOULD HELP IN CHANGING THE PARTICLE(ASSET) POSITIONS'''\n",
    "    '''INITIALIZING RANDOM POSITIONS(WEIGHTS) FOR ALL THE 100\n",
    "    *11 ASSETS'''\n",
    "    swarm_position = []\n",
    "    swarm_velocity = []\n",
    "    for particle in range(swarm_size):  # SWARM SIZE->PORTFOLIO\n",
    "        '''FOR EACH NEW PORTFOLIO, WE WOULD CREATING A LIST (position)'''\n",
    "        position = [0] * dimensions\n",
    "        velocity = [0] * dimensions\n",
    "        for dimension in range(dimensions):  # DIMENSIONS->ASSET\n",
    "\n",
    "            position[dimension] = random.random()  # random.random() would assign some random number between 0 and 1\n",
    "            velocity[dimension] = random.random()\n",
    "        '''position LIST OF EVERY NEW PORTFOLIO WOULD BE KEPT IN A SEPARATE LIST(swarm_position)'''\n",
    "        swarm_position.append(position)\n",
    "        swarm_velocity.append(velocity)\n",
    "\n",
    "    swarm_position = np.array([np.array(p) for p in swarm_position])  # COVERTING  swarm_position  list to an array\n",
    "    swarm_velocity = np.array([np.array(v) for v in swarm_velocity])  # COVERTING  swarm_velocities  list to an array\n",
    "\n",
    "    '''initial_swarm_positions IS A LIST , CONTAINING ALL THE INITIAL POSITIONS OF ALL THE ASSETS OF ALL THE PORTFOLIOS'''\n",
    "    initial_swarm_positions = swarm_position  # HERE IS THE MASTER FILE WHICH WE WOULD BE USING FOR COMPARISON\n",
    "    '''swarm_gbest,WE ARE ASSUMING THAT THE FIRST PORTFOLIO IS THE BEST OPTION AVAILABLE '''\n",
    "    swarm_gbest = initial_swarm_positions[0]\n",
    "\n",
    "    avg_sharpe_list = []\n",
    "    portfolio_return = []\n",
    "    portfolio_standard_deviation = []\n",
    "    portfolio_sortino = []\n",
    "    portfolio_semi_deviation = []\n",
    "    portfolio_sharpe = []\n",
    "    portfolio_weights = []\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        '''FOR EACH ITERATION'''\n",
    "        '''sharpe_pbest_all is a list which would contain the sharpe ratio of the portfolios,Finally at the end it would containing 100 sharpe ratios'''\n",
    "        sharpe_pbest_all = []\n",
    "        for particle in range(swarm_size):  # SWARM_SIZE->PORTFOLIOS\n",
    "            '''FOR EACH PORTFOLIO'''\n",
    "            for dimension in range(dimensions):  # DIMENSIONS->ASSETS\n",
    "                '''FOR EACH ASSET'''\n",
    "                '''HERE , WE WOULD BE UPDATING THE POSITIONS AND VELOCITES OF EACH OF THE ASSET PRESENT IN A PARTICULAR PORTFOLIO'''\n",
    "                r1 = random.random()  # random.random() WOULD BASICALLY GIVE YOU A VALUE BETWEEN 0 AND 1\n",
    "                r2 = random.random()\n",
    "                '''HERE WE WOULD BE CHANGING THE PRESENT PARTICLE(ASSET) POSITION \n",
    "                   AND FOR CHANGING THE POSITION,WE NEED TO CALCULATE THE NEW VELOCITY'''\n",
    "\n",
    "                '''BASIC FORMULA \n",
    "                   NEW VELOCITY->w*PRESENT VELOCITY + c1 * r1 * abs(INTIAL POSITION - PRESENT POSITION)+c2*r2*abs(GBEST POSITION - PRESENT POSITION)\n",
    "                   NEW POSITION->PRESENT POSITION + NEW VELOCITY\n",
    "                '''\n",
    "                w = (0.9 - 0.4) * ((\n",
    "                                           iterations - iteration) / iterations) + 0.4  # w at iteration, where initial_w = 0.9 & final_w = 0.4\n",
    "                c1 = (0.5 - 2.5) * (iteration / iterations) + 2.5  # c1 at iteration, where min_c1 = 0.5 & max_c1 = 2.5\n",
    "                c2 = (2.5 - 0.5) * (iteration / iterations) + 0.5  # c2 at iteration, where max_c2 = 2.5 & min_c2 = 0.5\n",
    "                swarm_velocity[particle][dimension] = w * swarm_velocity[particle][dimension] + c1 * r1 * abs(\n",
    "                    initial_swarm_positions[particle][dimension] - swarm_position[particle][dimension]) + c2 * r2 * abs(\n",
    "                    swarm_gbest[dimension] - swarm_position[particle][dimension])  # Update velocity in every dimension\n",
    "                swarm_position[particle][dimension] = swarm_position[particle][dimension] + swarm_velocity[particle][\n",
    "                    dimension]  # Update position in every direction\n",
    "\n",
    "            # AFTER 1 COMPLETE PORTFOLIO\n",
    "\n",
    "            '''AFTER CHANGING THE POSITIONS OF ALL THE ASSETS IN A PARTICULAR PORTFOLIO, WE WOULD FIND THE SHARPE RATIO OF THIS PORTFOLIO\n",
    "               AND WE WOULD STORE IT IN sharpe_pbest'''\n",
    "            sharpe_pbest = SHARPE(initial_swarm_positions[particle], mean_daily_returns,\n",
    "                                  cov_matrix)  # Evaluating sharpe of existing pbest position\n",
    "\n",
    "            '''THEN WE WOULD BE COMPARING THE sharpe_pbest WITH THE SHARPE RATIO OF THE INITIAL PORTFOLIO WHICH IS STORED IN initial_swarm_positions\n",
    "               ie COMPARING SHARPE RATIO OF THE PORTFOLIO OLD POSITION WITH SHARPE RATIO OF THE PORTFOLIO NEW POSITION'''\n",
    "\n",
    "            if SHARPE(swarm_position[particle], mean_daily_returns, cov_matrix) > sharpe_pbest:\n",
    "                '''IS THE NEW POSITION BETTER THAN THE EXISTING ONE'''\n",
    "                '''IF THE NEW POSITION IS BETTER, THEN UPDATE sharpe_pbest  and initial_swarm_positions[particle]'''\n",
    "                initial_swarm_positions[particle] = swarm_position[particle]  # Update pbest to new position\n",
    "                sharpe_pbest = SHARPE(initial_swarm_positions[particle], mean_daily_returns,\n",
    "                                      cov_matrix)  # Update sharpe of pbest\n",
    "            '''IF THE PORTFOLIO WITH NEW POSITION HAS HIGHER SHARPE RATIO THAN\n",
    "               THE OLD POSITION,APPEND SHARPE RATIO OF THE PORTFOLIO WRT TO NEW POSTION,\n",
    "               ELSE APPEND SHARPE RATIO OF THE PORTFOLIO WRT TO OLD POSTION '''\n",
    "            sharpe_pbest_all.append(sharpe_pbest)\n",
    "            '''AFTER ALL THE PORTFOLIOS(ie,AFTER ONE ITERATION) ARE DONE, WE WOULD SELECT THE BEST PORTFOLIO\n",
    "               WRT OF SHARPE RATIO AND COMPARE IT WITH THE SHARPE RATIO OF GLOBAL BEST(swarm_gbest PORTFOLIO)'''\n",
    "\n",
    "        # AFTER 1 COMPLETE ITERATION\n",
    "\n",
    "        if max(sharpe_pbest_all) > SHARPE(swarm_gbest, mean_daily_returns, cov_matrix):\n",
    "            ''' IS THE LARGEST SHARPE RATIO OF ALL THE PORTFOLIOS BETTER THEN gbest?'''\n",
    "            ''' IF YES, CHANGE THE gbest to max(sharpe_pbest_all)'''\n",
    "            max_index = sharpe_pbest_all.index(max(sharpe_pbest_all))\n",
    "            swarm_gbest = initial_swarm_positions[max_index]\n",
    "\n",
    "        '''AFTER 1 ITERATION IS DONE,ie GOING THROUGH ALL THE PORTFOLIOS AND FINDING THE BEST PORTFOLIO,\n",
    "           WE WOULD NOW PRINT THE VALUES\n",
    "        '''\n",
    "        ''' CALCULATING THE AVG SHARPE RATIO FOR THE ITERATION '''\n",
    "        avg_sharpe = sum(sharpe_pbest_all) / len(sharpe_pbest_all)\n",
    "\n",
    "        avg_sharpe_list.append(avg_sharpe)\n",
    "        '''NOW FOR PRINTING THE IMPORTANT DATA FROM EACH ITERATION, WE HAVE CREATED A SEPARATE FUNCTION(PRINT_EACH_ITERATION)'''\n",
    "        # portfolio_return, portfolio_standard_deviation, portfolio_sharpe,portfolio_semi_deviation, portfolio_sortino,  portfolio_weights =\n",
    "        # PRINT_EACH_ITERATION(iteration, swarm_gbest, mean_daily_returns, cov_matrix,cov_matrix_neg, portfolio_return, portfolio_standard_deviation, portfolio_sharpe,portfolio_semi_deviation, portfolio_sortino,  portfolio_weights)\n",
    "\n",
    "        weights_arr = [w / sum(swarm_gbest) for w in\n",
    "                       swarm_gbest]  # Making sure all weights represent proportions that add up to 1\n",
    "        weights = np.matrix(weights_arr)\n",
    "        port_return = np.round(np.sum(weights * mean_daily_returns.T) * trading_days, 2) / (\n",
    "            no_of_years)  # 1259 trading days over 5 year period\n",
    "        port_std_dev = np.round(np.sqrt(weights * cov_matrix * weights.T) * np.sqrt(trading_days), 2) / np.sqrt(\n",
    "            no_of_years)\n",
    "        port_std_dev = float(port_std_dev)\n",
    "        sharpe_ratio = (\n",
    "                               port_return - 0.0358) / port_std_dev  # 3.58 represents annual return of risk free security - 5-year US Treasury\n",
    "        port_semi_dev = np.round(np.sqrt(weights * cov_matrix_neg * weights.T) * np.sqrt(trading_days), 2) / np.sqrt(\n",
    "            no_of_years)\n",
    "        port_semi_dev = float(port_semi_dev)\n",
    "        sortino_ratio = (port_return - 0.0358) / (port_semi_dev)\n",
    "        portfolio_return.append(port_return)  # Adding portfolio return of a given PORTFOLIO  to  portfolio_return\n",
    "        portfolio_standard_deviation.append(\n",
    "            port_std_dev)  # Adding portfolio standard deviation of a given PORTFOLIO to a list of standard deviations to portfolio_vol\n",
    "        portfolio_sharpe.append(\n",
    "            sharpe_ratio)  # Adding portfolio sharpe ratio of a given PORTFOLIO  to   portfolio_sharpe\n",
    "        portfolio_semi_deviation.append(\n",
    "            port_semi_dev)  # Adding portfolio standard deviation of a given PORTFOLIO to a list of standard deviations to portfolio_vol\n",
    "        portfolio_sortino.append(\n",
    "            sortino_ratio)  # Adding portfolio sharpe ratio of a given PORTFOLIO  to   portfolio_sharpe\n",
    "        portfolio_weights.append(weights_arr)  # Adding portfolio weights of a given PORTFOLIO  to   portfolio_sharpe\n",
    "\n",
    "    # AFTER ALL THE ITERATIONS\n",
    "    return portfolio_return, portfolio_standard_deviation, portfolio_sharpe, portfolio_semi_deviation, portfolio_sortino, portfolio_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_Sharpe(start_date,end_date,pso_sharpe):\n",
    "    swarm_size=100\n",
    "    iterations=5\n",
    "    df = pd.read_csv('n50.csv', parse_dates=['Date'], index_col='Date')\n",
    "    df=df.loc[start_date:end_date]\n",
    "    n50=df\n",
    "    tdf = df.copy()  # deep copy\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    col = list(df.columns)\n",
    "    df1 = tdf.reset_index()\n",
    "    df1 = pd.DataFrame(df1)\n",
    "    df1 = list(df1.iloc[-1:])[1:]\n",
    "    stock_names = {}\n",
    "    for i in range(len(df1)):\n",
    "        stock_names[df1[i]] = i + 1\n",
    "    close = []\n",
    "    name = []\n",
    "    stock_no = []\n",
    "    daily_returns = []\n",
    "    for i in n50:\n",
    "        t = list(n50[i])  # finding the close price col for each asset\n",
    "        close.append(t)\n",
    "        name.append(i)\n",
    "        t = list(n50[i].pct_change())  # daily return for stock\n",
    "        daily_returns.append(t)\n",
    "\n",
    "    closed = []\n",
    "    for i in close:\n",
    "        for j in i:\n",
    "            closed.append(j)\n",
    "    close = closed\n",
    "\n",
    "    daily_returns_arr = []\n",
    "\n",
    "    for i in daily_returns:  # HERE IN THIS CODE ,WE ARE TRYING TO PLACE ALL THE DAILY RETURNS IN A SINGLE LIST Daily_Returnss----><2>\n",
    "        for j in i:\n",
    "            daily_returns_arr.append(j)\n",
    "    daily_returns = daily_returns_arr\n",
    "\n",
    "    name_arr = []\n",
    "\n",
    "    x = n50.shape[0]  # FINDING NO OF ROWS, THE REASON IS EACH STOCK IS REPEATING X TIMES\n",
    "\n",
    "    for i in stock_names:  # ------><3>\n",
    "        for j in range(x):\n",
    "            name_arr.append(i)\n",
    "\n",
    "    name = name_arr\n",
    "    data = {}\n",
    "    data['Close'] = close\n",
    "    data['Daily_returns'] = daily_returns\n",
    "    data['Name'] = name\n",
    "    data = pd.DataFrame(data)\n",
    "    data.isna().sum()\n",
    "    data = data.fillna(0)  \n",
    "    dimensions = len(stock_names)  \n",
    "    avg_sharpe_list = []\n",
    "    portfolio_return = []\n",
    "    portfolio_standard_deviation = []\n",
    "    portfolio_sortino = []\n",
    "    portfolio_semi_deviation = []\n",
    "    portfolio_sharpe = []\n",
    "    portfolio_weights = []\n",
    "    portfolio_return, portfolio_standard_deviation, portfolio_sharpe, portfolio_semi_deviation, portfolio_sortino, portfolio_weights = PSO_OPTIMIZER(\n",
    "    swarm_size, iterations)\n",
    "    sharpe_portfolio = {'Returns': portfolio_return, 'Standard Deviation': portfolio_standard_deviation,\n",
    "                    'Sharpe Ratio': portfolio_sharpe}\n",
    "    for counter, symbol in enumerate(n50.columns):\n",
    "        sharpe_portfolio[symbol + \" Weight\"] = [Weight[counter] for Weight in portfolio_weights]\n",
    "    sharpe_pc = pd.DataFrame(sharpe_portfolio)\n",
    "    sharpe_pc.loc[:, :] *= 100\n",
    "    sharpe_pc.loc[:, 'Sharpe Ratio'] /= 100\n",
    "    sharpe_optimal=sharpe_pc.iloc[sharpe_pc['Sharpe Ratio'].idxmax()]\n",
    "    sharpe_optimal=sharpe_optimal.to_frame()\n",
    "    sharpe_optimal=sharpe_optimal.transpose()\n",
    "    print(sharpe_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=\"2016-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_index=df.index[df['Date'] == start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date=\"2020-09-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date_index=df.index[df['Date']== end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_lookback=\"2020-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_lookback_index=df.index[df['Date'] == start_date_lookback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date_lookback=\"2020-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date_lookback_index=df.index[df['Date']== end_date_lookback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19012/224007685.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mend_date_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minputweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPSO_Sharpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_date_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mend_date_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpso_sharpe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpso_sharpe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPSO_Sharpe_lookback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_date_lookback_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mend_date_lookback_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mend_date_lookback_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmvo_sortino\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_date_lookback_index\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mend_date_lookback_index\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19012/1589153502.py\u001b[0m in \u001b[0;36mPSO_Sharpe\u001b[1;34m(start_date, end_date, pso_sharpe)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mportfolio_sharpe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mportfolio_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     portfolio_return, portfolio_standard_deviation, portfolio_sharpe, portfolio_semi_deviation, portfolio_sortino, portfolio_weights = PSO_OPTIMIZER(\n\u001b[0m\u001b[0;32m     67\u001b[0m     swarm_size, iterations)\n\u001b[0;32m     68\u001b[0m     sharpe_portfolio = {'Returns': portfolio_return, 'Standard Deviation': portfolio_standard_deviation,\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19012/507207010.py\u001b[0m in \u001b[0;36mPSO_OPTIMIZER\u001b[1;34m(swarm_size, iterations)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mneg_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstock_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mindv_stock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mName\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstock\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mavg_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindv_stock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDaily_returns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stock_names' is not defined"
     ]
    }
   ],
   "source": [
    "while df.iloc[end_date_index].Date.values[0]:\n",
    "    inputweights=PSO_Sharpe(df.iloc[start_date_index].Date.values[0],df.iloc[end_date_index].Date.values[0],pso_sharpe)\n",
    "    pso_sharpe=PSO_Sharpe_lookback(df.iloc[start_date_lookback_index].Date.values[0],df.iloc[end_date_lookback_index].Date.values[0],df.iloc[end_date_lookback_index+1].Date.values[0],mvo_sortino,inputweights)\n",
    "    start_date_lookback_index+=1\n",
    "    end_date_lookback_index+=1\n",
    "    start_date_index+=1\n",
    "    end_date_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
