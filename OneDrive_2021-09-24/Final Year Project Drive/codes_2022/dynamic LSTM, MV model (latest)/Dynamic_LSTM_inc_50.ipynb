{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30183,
     "status": "ok",
     "timestamp": 1623817280712,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "SMicyxToqMya",
    "outputId": "a6aa09af-7659-442f-d4b6-94ac8e1dfdac"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3153,
     "status": "ok",
     "timestamp": 1623817299021,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "0ZUpAr9hmscg",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np           \n",
    "import numpy\n",
    "from numpy import array\n",
    "# import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1623817347911,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "Mnjvw3h0S2Yu",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#code for MAPE, referred from the url: https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-percentage-error\n",
    "#'eps' is an arbitrary small yet strictly positive number to avoid undefined results when y is zero.\n",
    "def mean_absolute_percentage_error(y_true, y_pred):                                        \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    eps=0.01\n",
    "    for i in range(len(y_true)):\n",
    "      if y_true[i]==0.00:\n",
    "        y_true[i]=eps\n",
    "    return np.mean((np.abs(y_true - y_pred)) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1623817351033,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "eSaVvpyV29Hw",
    "outputId": "7d90ffa5-805e-4ca5-85f0-0887320488b9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x=pd.read_csv('n50.csv',parse_dates=['Date'],index_col='Date')\n",
    "x = x.loc[\"2016-01-01\" :]                         #Since 2016-01-01, 5y(1234rows till 2020-12-31), + year 2021's rows (till 30th of April)\n",
    "y=x.copy()                                        #deep copy\n",
    "x.reset_index(drop=True, inplace=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1623817680052,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "WePgv9O6r0I_",
    "outputId": "6b53d356-22a2-4cb5-9112-9a35c2ae048e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "stonks=[]\n",
    "for i in x:\n",
    "  stonks.append(i)\n",
    "len(stonks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1623817682621,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "JfmGW-eD2p73",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "alldata=x   #the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1623817685225,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "NuN2s7Ogwz1k",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "timesteps=60                                     #lstm hyperparameters \"Subject to be tuned\"\n",
    "epoch=100\n",
    "batchSize=32\n",
    "ineurons=175\n",
    "hneurons=187\n",
    "after2020=len(y.loc[\"2021-01-01\" : ])                    #number of days after 31-12-2020 \"automated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1623817687733,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "DXcGk0vzctud",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):         # convert an array of values into a dataset matrix which will be used to train the lstm model.\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step):\n",
    "\t\ta = dataset[i:(i+time_step), 0]               #i=0, 0,1,2,3-----(timesteps-1)  -> timesteps\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1623817689152,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "a4weFefCyPmt",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def forcast(df1, timesteps, epoch, batchSize, ineurons, hneurons, after2020):             \n",
    "  scaler=MinMaxScaler(feature_range=(0,1))   \n",
    "  df1=scaler.fit_transform(np.array(df1).reshape(-1,1))           #minmax scalar transformation of data\n",
    "\n",
    "  before_2021_data_length=int(len(df1)-after2020)                 #length of data before 2021\n",
    "  training_size=int(before_2021_data_length*0.80)                 #80% of training size, refered from Yadav et al (2020) (Science Direct)\n",
    "  train_data=df1[0:training_size,:]                              \n",
    "  test_data=df1[training_size:before_2021_data_length,:1]         #20% of testing data, refered from Yadav et al (2020) (Science Direct)                \n",
    "  inpdata=df1[before_2021_data_length-timesteps:len(df1),:1]      #getting the data from 01-01-2021 onwards\n",
    "\n",
    "\n",
    "  #reshape into X=t,t+1,t+2,t+3,........t+\"timestep-1\" and Y=t+\"timestep\"\n",
    "  X_train, y_train = create_dataset(train_data, timesteps)\n",
    "  x_inp, y_inp = create_dataset(inpdata, timesteps)\n",
    "  x_test, y_test = create_dataset(test_data,timesteps)\n",
    "\n",
    "  X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1) \n",
    "  x_inp = x_inp.reshape(x_inp.shape[0],x_inp.shape[1] , 1)        #reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "  x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1)\n",
    "\n",
    "  # initialising stacked lstm\n",
    "  model=Sequential()\n",
    "  model.add(LSTM(ineurons,return_sequences=True,input_shape=(timesteps,1),activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(hneurons,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(hneurons,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(hneurons,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(hneurons,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(hneurons,activation='tanh', dropout=0.1))\n",
    "  model.add(Dense(1,activation='sigmoid'))\n",
    "  model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "  model.fit(X_train,y_train,validation_data=(x_test,y_test),epochs=epoch,batch_size=batchSize,verbose=1)     # training of the model\n",
    "  \n",
    "  test_predict=model.predict(x_test)                    #prediction using test data as input\n",
    "\n",
    "  #performance metrics between, original test data and predicted test data\n",
    "  msetst =mean_squared_error(y_test,test_predict)\n",
    "  rmsetst=math.sqrt(msetst)\n",
    "  maetst =mean_absolute_error(y_test,test_predict)\n",
    "  r2tst  =r2_score(y_test,test_predict)\n",
    "  mapetst=mean_absolute_percentage_error(y_test,test_predict)\n",
    "  tstlst =[msetst,rmsetst,maetst,r2tst,mapetst]\n",
    "\n",
    "\n",
    "  #model is trained again on the test data so as to increase the learning (it is often termed as incremental learning)\n",
    "  #refered from url: https://www.justintodata.com/forecast-time-series-lstm-with-tensorflow-keras/#step-2-transforming-the-dataset-for-tensorflow-keras\n",
    "  #refered from url: https://github.com/keras-team/keras/issues/4446\n",
    "  model.fit(x_test,y_test,epochs=epoch,batch_size=batchSize,verbose=1)\n",
    "  \n",
    "  out_predict=model.predict(x_inp)                      #dynamic prediction of the stock's closing price from 01-01-2021 onwards\n",
    "\n",
    "  #performance metrics between, original data(after 31-12-2020) and dynamically predicted data (after 31-12-2020)\n",
    "  mseinp =mean_squared_error(y_inp,out_predict)\n",
    "  rmseinp=math.sqrt(mseinp)\n",
    "  maeinp =mean_absolute_error(y_inp,out_predict)\n",
    "  r2inp  =r2_score(y_inp,out_predict)\n",
    "  mapeinp=mean_absolute_percentage_error(y_inp,out_predict)\n",
    "  inplst =[mseinp,rmseinp,maeinp,r2inp,mapeinp]\n",
    "\n",
    "\n",
    "  lst=[]\n",
    "  for i in out_predict:\n",
    "    lst.append(i)\n",
    "\n",
    "  p=train_data.tolist()\n",
    "  q=test_data.tolist()\n",
    "  p.extend(q)                                         #appending train and test data to make dataset before 2021 (data till 31-12-2020)\n",
    "  p.extend(lst)                                       #appending the data, forcasted from 01-01-2021 onwards, to the data till 31-12-2020\n",
    "  p=scaler.inverse_transform(p).tolist()\n",
    "\n",
    "  return pd.DataFrame(p), tstlst, inplst\n",
    "  #returns a dataframe, tstlst => test performance metrics, inplst => forcasted data performance metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7836262,
     "status": "ok",
     "timestamp": 1623828011697,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "wcpJPAnHwTFT",
    "outputId": "1104aab4-b8c2-4d8d-f69f-91b07f01129f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mtest=[]\n",
    "mdynamic=[]\n",
    "fdata=pd.DataFrame()\n",
    "for i in alldata:                                   # this for loop will be iterated for 42 times i.e. for each column of the original dataset\n",
    "  temp=alldata[i]\n",
    "  ftemp,trmse,drmse=forcast(temp, timesteps, epoch, batchSize, ineurons, hneurons, after2020)    #hyperparameters are provided as input here\n",
    "  fdata = pd.concat([fdata,ftemp],axis = 1)\n",
    "  mtest.append(trmse)\n",
    "  mdynamic.append(drmse)\n",
    "fdata.columns=stonks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623828011698,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "SG5uqRTl44SQ",
    "outputId": "fe99b623-0ad9-499a-9a31-6cd359d26da1",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fdata # dataset with 2021 rows forcasted dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1623828011698,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "HUIDhvD2LiOI",
    "outputId": "9c2792d0-8945-47eb-d82c-076d4b798572",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "alldata # dataset with original 2021 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1623828012399,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "om96PmMpsqZk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fdata.to_csv('data_inc/fdata.csv')   #dataset saved in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1623828012400,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "8f6fEyrzrDGr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clm=['MSE','RMSE','MAE','R2','MAPE']\n",
    "pd.DataFrame(mtest,index=stonks,columns=clm).to_csv('data_inc/mtest.csv') #metric values saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1623828013312,
     "user": {
      "displayName": "Dhiraj Patidar",
      "photoUrl": "",
      "userId": "01911352281812304855"
     },
     "user_tz": -330
    },
    "id": "1T-KGR6osbBQ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(mdynamic,index=stonks,columns=clm).to_csv('data_inc/mdynamic.csv') #metric values saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Dynamic_LSTM_inc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}