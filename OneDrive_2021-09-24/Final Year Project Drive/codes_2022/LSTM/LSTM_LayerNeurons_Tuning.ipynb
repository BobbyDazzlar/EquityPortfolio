{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp/ipykernel_79336/1794188618.py:24: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#minimizing RMSE\n",
    "import optuna\n",
    "import numpy\n",
    "from numpy import array\n",
    "import math\n",
    "\n",
    "#LSTM scores\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#LSTM\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "#Neuron Parameters\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>HDFCBANK</th>\n",
       "      <th>HINDALCO</th>\n",
       "      <th>HINDUNILVR</th>\n",
       "      <th>HDFC</th>\n",
       "      <th>...</th>\n",
       "      <th>JSWSTEEL</th>\n",
       "      <th>KOTAKBANK</th>\n",
       "      <th>NESTLEIND</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>WIPRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>850.608887</td>\n",
       "      <td>602.348328</td>\n",
       "      <td>1978.543457</td>\n",
       "      <td>1374.428223</td>\n",
       "      <td>1108.503052</td>\n",
       "      <td>385.106506</td>\n",
       "      <td>528.506653</td>\n",
       "      <td>82.550529</td>\n",
       "      <td>792.340698</td>\n",
       "      <td>1169.114624</td>\n",
       "      <td>...</td>\n",
       "      <td>93.927940</td>\n",
       "      <td>725.564270</td>\n",
       "      <td>5311.719238</td>\n",
       "      <td>486.556549</td>\n",
       "      <td>11121.029297</td>\n",
       "      <td>1082.013306</td>\n",
       "      <td>219.908173</td>\n",
       "      <td>461.389832</td>\n",
       "      <td>340.842285</td>\n",
       "      <td>202.975677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852.593201</td>\n",
       "      <td>598.059875</td>\n",
       "      <td>1954.307739</td>\n",
       "      <td>1368.077148</td>\n",
       "      <td>1096.297607</td>\n",
       "      <td>385.152100</td>\n",
       "      <td>519.647644</td>\n",
       "      <td>78.515373</td>\n",
       "      <td>794.607056</td>\n",
       "      <td>1130.328369</td>\n",
       "      <td>...</td>\n",
       "      <td>95.546753</td>\n",
       "      <td>703.665161</td>\n",
       "      <td>5205.810547</td>\n",
       "      <td>476.948639</td>\n",
       "      <td>10804.255859</td>\n",
       "      <td>1061.057739</td>\n",
       "      <td>219.481003</td>\n",
       "      <td>458.151581</td>\n",
       "      <td>340.212952</td>\n",
       "      <td>203.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>871.807617</td>\n",
       "      <td>592.664673</td>\n",
       "      <td>1940.843384</td>\n",
       "      <td>1365.361816</td>\n",
       "      <td>1094.199951</td>\n",
       "      <td>383.717926</td>\n",
       "      <td>515.715759</td>\n",
       "      <td>80.314178</td>\n",
       "      <td>784.385376</td>\n",
       "      <td>1123.546631</td>\n",
       "      <td>...</td>\n",
       "      <td>99.058762</td>\n",
       "      <td>706.109497</td>\n",
       "      <td>5199.016113</td>\n",
       "      <td>481.668732</td>\n",
       "      <td>10867.756836</td>\n",
       "      <td>1051.810791</td>\n",
       "      <td>234.346603</td>\n",
       "      <td>463.031219</td>\n",
       "      <td>336.630768</td>\n",
       "      <td>203.139801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858.013977</td>\n",
       "      <td>603.474854</td>\n",
       "      <td>1933.413330</td>\n",
       "      <td>1381.469727</td>\n",
       "      <td>1084.378296</td>\n",
       "      <td>383.080475</td>\n",
       "      <td>517.997192</td>\n",
       "      <td>78.320908</td>\n",
       "      <td>779.852783</td>\n",
       "      <td>1123.453613</td>\n",
       "      <td>...</td>\n",
       "      <td>96.781441</td>\n",
       "      <td>701.969116</td>\n",
       "      <td>5251.443359</td>\n",
       "      <td>494.631134</td>\n",
       "      <td>11188.242188</td>\n",
       "      <td>1066.431152</td>\n",
       "      <td>229.604980</td>\n",
       "      <td>465.870178</td>\n",
       "      <td>336.776001</td>\n",
       "      <td>202.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>844.413879</td>\n",
       "      <td>603.380981</td>\n",
       "      <td>1921.943726</td>\n",
       "      <td>1356.088257</td>\n",
       "      <td>1074.604370</td>\n",
       "      <td>375.636505</td>\n",
       "      <td>512.706055</td>\n",
       "      <td>74.528839</td>\n",
       "      <td>758.761841</td>\n",
       "      <td>1095.722656</td>\n",
       "      <td>...</td>\n",
       "      <td>93.868484</td>\n",
       "      <td>690.046875</td>\n",
       "      <td>5177.484863</td>\n",
       "      <td>485.550232</td>\n",
       "      <td>10725.758789</td>\n",
       "      <td>1061.796509</td>\n",
       "      <td>213.500595</td>\n",
       "      <td>453.183197</td>\n",
       "      <td>333.096954</td>\n",
       "      <td>200.568176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>2557.899902</td>\n",
       "      <td>4736.549805</td>\n",
       "      <td>10001.750000</td>\n",
       "      <td>3526.107910</td>\n",
       "      <td>3784.350098</td>\n",
       "      <td>918.745850</td>\n",
       "      <td>1404.800049</td>\n",
       "      <td>348.350006</td>\n",
       "      <td>2360.649902</td>\n",
       "      <td>2509.800049</td>\n",
       "      <td>...</td>\n",
       "      <td>655.799988</td>\n",
       "      <td>1759.650024</td>\n",
       "      <td>16779.318359</td>\n",
       "      <td>1937.849976</td>\n",
       "      <td>28062.599609</td>\n",
       "      <td>3085.706299</td>\n",
       "      <td>940.750000</td>\n",
       "      <td>962.200012</td>\n",
       "      <td>1479.849976</td>\n",
       "      <td>480.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>2574.350098</td>\n",
       "      <td>4865.049805</td>\n",
       "      <td>10091.349609</td>\n",
       "      <td>3528.100342</td>\n",
       "      <td>3908.949951</td>\n",
       "      <td>918.795288</td>\n",
       "      <td>1438.699951</td>\n",
       "      <td>366.250000</td>\n",
       "      <td>2379.850098</td>\n",
       "      <td>2518.399902</td>\n",
       "      <td>...</td>\n",
       "      <td>665.900024</td>\n",
       "      <td>1750.300049</td>\n",
       "      <td>16688.214844</td>\n",
       "      <td>1988.650024</td>\n",
       "      <td>28098.550781</td>\n",
       "      <td>3116.754150</td>\n",
       "      <td>977.750000</td>\n",
       "      <td>969.250000</td>\n",
       "      <td>1495.099976</td>\n",
       "      <td>485.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2614.550049</td>\n",
       "      <td>5280.899902</td>\n",
       "      <td>10489.299805</td>\n",
       "      <td>3465.881348</td>\n",
       "      <td>3882.600098</td>\n",
       "      <td>913.799988</td>\n",
       "      <td>1476.800049</td>\n",
       "      <td>362.600006</td>\n",
       "      <td>2406.550049</td>\n",
       "      <td>2577.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>662.650024</td>\n",
       "      <td>1811.449951</td>\n",
       "      <td>16543.800781</td>\n",
       "      <td>1997.300049</td>\n",
       "      <td>28687.550781</td>\n",
       "      <td>3108.892822</td>\n",
       "      <td>971.400024</td>\n",
       "      <td>977.400024</td>\n",
       "      <td>1508.849976</td>\n",
       "      <td>489.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2613.449951</td>\n",
       "      <td>5484.850098</td>\n",
       "      <td>11176.549805</td>\n",
       "      <td>3456.067871</td>\n",
       "      <td>3910.850098</td>\n",
       "      <td>909.549988</td>\n",
       "      <td>1472.500000</td>\n",
       "      <td>372.149994</td>\n",
       "      <td>2407.600098</td>\n",
       "      <td>2538.850098</td>\n",
       "      <td>...</td>\n",
       "      <td>726.500000</td>\n",
       "      <td>1805.000000</td>\n",
       "      <td>16502.550781</td>\n",
       "      <td>2024.050049</td>\n",
       "      <td>28444.349609</td>\n",
       "      <td>3100.085693</td>\n",
       "      <td>1031.349976</td>\n",
       "      <td>976.900024</td>\n",
       "      <td>1506.800049</td>\n",
       "      <td>489.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>2536.399902</td>\n",
       "      <td>5451.899902</td>\n",
       "      <td>11041.650391</td>\n",
       "      <td>3436.241455</td>\n",
       "      <td>4062.350098</td>\n",
       "      <td>898.950012</td>\n",
       "      <td>1412.300049</td>\n",
       "      <td>364.399994</td>\n",
       "      <td>2353.750000</td>\n",
       "      <td>2420.100098</td>\n",
       "      <td>...</td>\n",
       "      <td>717.849976</td>\n",
       "      <td>1748.800049</td>\n",
       "      <td>16309.250000</td>\n",
       "      <td>1994.500000</td>\n",
       "      <td>27910.500000</td>\n",
       "      <td>3020.873291</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>960.400024</td>\n",
       "      <td>1491.650024</td>\n",
       "      <td>492.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASIANPAINT   BAJFINANCE    BAJAJFINSV    BRITANNIA     DIVISLAB  \\\n",
       "0      850.608887   602.348328   1978.543457  1374.428223  1108.503052   \n",
       "1      852.593201   598.059875   1954.307739  1368.077148  1096.297607   \n",
       "2      871.807617   592.664673   1940.843384  1365.361816  1094.199951   \n",
       "3      858.013977   603.474854   1933.413330  1381.469727  1084.378296   \n",
       "4      844.413879   603.380981   1921.943726  1356.088257  1074.604370   \n",
       "...           ...          ...           ...          ...          ...   \n",
       "1309  2557.899902  4736.549805  10001.750000  3526.107910  3784.350098   \n",
       "1310  2574.350098  4865.049805  10091.349609  3528.100342  3908.949951   \n",
       "1311  2614.550049  5280.899902  10489.299805  3465.881348  3882.600098   \n",
       "1312  2613.449951  5484.850098  11176.549805  3456.067871  3910.850098   \n",
       "1313  2536.399902  5451.899902  11041.650391  3436.241455  4062.350098   \n",
       "\n",
       "         HCLTECH     HDFCBANK    HINDALCO   HINDUNILVR         HDFC  ...  \\\n",
       "0     385.106506   528.506653   82.550529   792.340698  1169.114624  ...   \n",
       "1     385.152100   519.647644   78.515373   794.607056  1130.328369  ...   \n",
       "2     383.717926   515.715759   80.314178   784.385376  1123.546631  ...   \n",
       "3     383.080475   517.997192   78.320908   779.852783  1123.453613  ...   \n",
       "4     375.636505   512.706055   74.528839   758.761841  1095.722656  ...   \n",
       "...          ...          ...         ...          ...          ...  ...   \n",
       "1309  918.745850  1404.800049  348.350006  2360.649902  2509.800049  ...   \n",
       "1310  918.795288  1438.699951  366.250000  2379.850098  2518.399902  ...   \n",
       "1311  913.799988  1476.800049  362.600006  2406.550049  2577.000000  ...   \n",
       "1312  909.549988  1472.500000  372.149994  2407.600098  2538.850098  ...   \n",
       "1313  898.950012  1412.300049  364.399994  2353.750000  2420.100098  ...   \n",
       "\n",
       "        JSWSTEEL    KOTAKBANK     NESTLEIND     RELIANCE      SHREECEM  \\\n",
       "0      93.927940   725.564270   5311.719238   486.556549  11121.029297   \n",
       "1      95.546753   703.665161   5205.810547   476.948639  10804.255859   \n",
       "2      99.058762   706.109497   5199.016113   481.668732  10867.756836   \n",
       "3      96.781441   701.969116   5251.443359   494.631134  11188.242188   \n",
       "4      93.868484   690.046875   5177.484863   485.550232  10725.758789   \n",
       "...          ...          ...           ...          ...           ...   \n",
       "1309  655.799988  1759.650024  16779.318359  1937.849976  28062.599609   \n",
       "1310  665.900024  1750.300049  16688.214844  1988.650024  28098.550781   \n",
       "1311  662.650024  1811.449951  16543.800781  1997.300049  28687.550781   \n",
       "1312  726.500000  1805.000000  16502.550781  2024.050049  28444.349609   \n",
       "1313  717.849976  1748.800049  16309.250000  1994.500000  27910.500000   \n",
       "\n",
       "              TCS    TATASTEEL       TECHM        TITAN       WIPRO  \n",
       "0     1082.013306   219.908173  461.389832   340.842285  202.975677  \n",
       "1     1061.057739   219.481003  458.151581   340.212952  203.431641  \n",
       "2     1051.810791   234.346603  463.031219   336.630768  203.139801  \n",
       "3     1066.431152   229.604980  465.870178   336.776001  202.483200  \n",
       "4     1061.796509   213.500595  453.183197   333.096954  200.568176  \n",
       "...           ...          ...         ...          ...         ...  \n",
       "1309  3085.706299   940.750000  962.200012  1479.849976  480.299988  \n",
       "1310  3116.754150   977.750000  969.250000  1495.099976  485.049988  \n",
       "1311  3108.892822   971.400024  977.400024  1508.849976  489.299988  \n",
       "1312  3100.085693  1031.349976  976.900024  1506.800049  489.850006  \n",
       "1313  3020.873291  1034.000000  960.400024  1491.650024  492.750000  \n",
       "\n",
       "[1314 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pd.read_csv('n50.csv',parse_dates=['Date'],index_col='Date')\n",
    "x = x.loc[\"2016-01-01\" :]                         #Since 2016-01-01, 5y(1234rows till 2020-12-31), + year 2021's rows (till 30th of April)\n",
    "y=x.copy()                                        #deep copy\n",
    "x.reset_index(drop=True, inplace=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):         # convert an array of values into a dataset matrix which will be used to train the lstm model.\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step):\n",
    "\t\ta = dataset[i:(i+time_step), 0]               #i=0, 0,1,2,3-----(timesteps-1)  -> timesteps\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(x).reshape(-1,1))   \n",
    "after2020=len(y.loc[\"2021-01-01\" : ])                    \n",
    "before_2021_data_length=int(len(df1)-after2020)                 #length of data before 2021\n",
    "training_size=int(before_2021_data_length*0.80)                 #80% of training size, refered from Yadav et al (2020) (Science Direct)\n",
    "train_data=df1[0:training_size,:]\n",
    "test_data=df1[training_size:before_2021_data_length,:1]\n",
    "inpdata=df1[before_2021_data_length-60:len(df1),:1]\n",
    "\n",
    "\n",
    "X_train, y_train = create_dataset(train_data, 60)\n",
    "x_inp, y_inp = create_dataset(inpdata, 60)\n",
    "x_test, y_test = create_dataset(test_data,60)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "x_inp = x_inp.reshape(x_inp.shape[0],x_inp.shape[1] , 1)        #reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  # initialising stacked lstm\n",
    "  model=Sequential()\n",
    "  for i in range(hp.Int('num_layers', 2, 7)):\n",
    "    model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=8),\n",
    "                               activation='tanh'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner=RandomSearch(\n",
    "    build_model,\n",
    "    objective='mean_squared_error',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='LayerNeurons',\n",
    "    project_name='parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 7, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 8, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 8, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 42s]\n",
      "mean_squared_error: 0.014974540409942469\n",
      "\n",
      "Best mean_squared_error So Far: 0.014974540409942469\n",
      "Total elapsed time: 00h 23m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in LayerNeurons\\parameters\n",
      "Showing 10 best trials\n",
      "Objective(name='mean_squared_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 264\n",
      "learning_rate: 0.0001\n",
      "units_1: 80\n",
      "units_2: 416\n",
      "units_3: 160\n",
      "units_4: 472\n",
      "units_5: 440\n",
      "Score: 0.014974540409942469\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 336\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "Score: 0.014976891068120798\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 160\n",
      "learning_rate: 0.0001\n",
      "units_1: 216\n",
      "units_2: 40\n",
      "units_3: 312\n",
      "units_4: 32\n",
      "Score: 0.015012149388591448\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 96\n",
      "learning_rate: 0.0001\n",
      "units_1: 360\n",
      "units_2: 368\n",
      "units_3: 448\n",
      "units_4: 80\n",
      "units_5: 32\n",
      "Score: 0.015016817798217138\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 232\n",
      "learning_rate: 0.01\n",
      "units_1: 448\n",
      "units_2: 200\n",
      "units_3: 368\n",
      "units_4: 288\n",
      "Score: 0.015100117462376753\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters:\n",
    "#num_layers: 5\n",
    "#units_0: 264\n",
    "#units_1: 80\n",
    "#units_2: 416\n",
    "#units_3: 160\n",
    "#units_4: 472\n",
    "#units_5: 440\n",
    "#learning_rate: 0.0001\n",
    "#Score: 0.014974540409942469"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}