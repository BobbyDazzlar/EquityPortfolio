{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hE1JUvHSxL3o",
    "outputId": "895d9a94-57de-4adb-9fdf-cd1463277a61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 5.1 MB/s \n",
      "\u001b[?25hCollecting cliff\n",
      "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 3.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.27)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
      "\u001b[K     |████████████████████████████████| 209 kB 38.0 MB/s \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.2)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 2.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 35.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.3 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 37.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=e2613b0a2cb755b5ff361af8d9b3d917a986f23facadb682185ba1710de42eaf\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "!pip install optuna\n",
    "import optuna\n",
    "from numpy import array\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8R5OMbBlxL3s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#code for MAPE, referred from the url: https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-percentage-error\n",
    "#'eps' is an arbitrary small yet strictly positive number to avoid undefined results when y is zero.\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    eps=0.01\n",
    "    for i in range(len(y_true)):\n",
    "      if y_true[i]==0.00:\n",
    "        y_true[i]=eps\n",
    "    return np.mean((np.abs(y_true - y_pred)) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "2Mo7k6aTxL3t",
    "outputId": "124605fa-4b31-4ecb-dae5-910f9d6ab64b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-af7857a1-a1f9-42b4-99f5-ca7d69187520\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>HDFCBANK</th>\n",
       "      <th>HINDALCO</th>\n",
       "      <th>HINDUNILVR</th>\n",
       "      <th>HDFC</th>\n",
       "      <th>ICICIBANK</th>\n",
       "      <th>INFY</th>\n",
       "      <th>JSWSTEEL</th>\n",
       "      <th>KOTAKBANK</th>\n",
       "      <th>NESTLEIND</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>WIPRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>850.608887</td>\n",
       "      <td>602.348328</td>\n",
       "      <td>1978.543457</td>\n",
       "      <td>1374.428223</td>\n",
       "      <td>1108.503052</td>\n",
       "      <td>385.106506</td>\n",
       "      <td>528.506653</td>\n",
       "      <td>82.550529</td>\n",
       "      <td>792.340698</td>\n",
       "      <td>1169.114624</td>\n",
       "      <td>227.737686</td>\n",
       "      <td>482.005096</td>\n",
       "      <td>93.927940</td>\n",
       "      <td>725.564270</td>\n",
       "      <td>5311.719238</td>\n",
       "      <td>486.556549</td>\n",
       "      <td>11121.029297</td>\n",
       "      <td>1082.013306</td>\n",
       "      <td>219.908173</td>\n",
       "      <td>461.389832</td>\n",
       "      <td>340.842285</td>\n",
       "      <td>202.975677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852.593201</td>\n",
       "      <td>598.059875</td>\n",
       "      <td>1954.307739</td>\n",
       "      <td>1368.077148</td>\n",
       "      <td>1096.297607</td>\n",
       "      <td>385.152100</td>\n",
       "      <td>519.647644</td>\n",
       "      <td>78.515373</td>\n",
       "      <td>794.607056</td>\n",
       "      <td>1130.328369</td>\n",
       "      <td>221.286560</td>\n",
       "      <td>470.513763</td>\n",
       "      <td>95.546753</td>\n",
       "      <td>703.665161</td>\n",
       "      <td>5205.810547</td>\n",
       "      <td>476.948639</td>\n",
       "      <td>10804.255859</td>\n",
       "      <td>1061.057739</td>\n",
       "      <td>219.481003</td>\n",
       "      <td>458.151581</td>\n",
       "      <td>340.212952</td>\n",
       "      <td>203.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>871.807617</td>\n",
       "      <td>592.664673</td>\n",
       "      <td>1940.843384</td>\n",
       "      <td>1365.361816</td>\n",
       "      <td>1094.199951</td>\n",
       "      <td>383.717926</td>\n",
       "      <td>515.715759</td>\n",
       "      <td>80.314178</td>\n",
       "      <td>784.385376</td>\n",
       "      <td>1123.546631</td>\n",
       "      <td>222.282349</td>\n",
       "      <td>468.398560</td>\n",
       "      <td>99.058762</td>\n",
       "      <td>706.109497</td>\n",
       "      <td>5199.016113</td>\n",
       "      <td>481.668732</td>\n",
       "      <td>10867.756836</td>\n",
       "      <td>1051.810791</td>\n",
       "      <td>234.346603</td>\n",
       "      <td>463.031219</td>\n",
       "      <td>336.630768</td>\n",
       "      <td>203.139801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858.013977</td>\n",
       "      <td>603.474854</td>\n",
       "      <td>1933.413330</td>\n",
       "      <td>1381.469727</td>\n",
       "      <td>1084.378296</td>\n",
       "      <td>383.080475</td>\n",
       "      <td>517.997192</td>\n",
       "      <td>78.320908</td>\n",
       "      <td>779.852783</td>\n",
       "      <td>1123.453613</td>\n",
       "      <td>216.567245</td>\n",
       "      <td>466.348938</td>\n",
       "      <td>96.781441</td>\n",
       "      <td>701.969116</td>\n",
       "      <td>5251.443359</td>\n",
       "      <td>494.631134</td>\n",
       "      <td>11188.242188</td>\n",
       "      <td>1066.431152</td>\n",
       "      <td>229.604980</td>\n",
       "      <td>465.870178</td>\n",
       "      <td>336.776001</td>\n",
       "      <td>202.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>844.413879</td>\n",
       "      <td>603.380981</td>\n",
       "      <td>1921.943726</td>\n",
       "      <td>1356.088257</td>\n",
       "      <td>1074.604370</td>\n",
       "      <td>375.636505</td>\n",
       "      <td>512.706055</td>\n",
       "      <td>74.528839</td>\n",
       "      <td>758.761841</td>\n",
       "      <td>1095.722656</td>\n",
       "      <td>213.666412</td>\n",
       "      <td>458.259216</td>\n",
       "      <td>93.868484</td>\n",
       "      <td>690.046875</td>\n",
       "      <td>5177.484863</td>\n",
       "      <td>485.550232</td>\n",
       "      <td>10725.758789</td>\n",
       "      <td>1061.796509</td>\n",
       "      <td>213.500595</td>\n",
       "      <td>453.183197</td>\n",
       "      <td>333.096954</td>\n",
       "      <td>200.568176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>2557.899902</td>\n",
       "      <td>4736.549805</td>\n",
       "      <td>10001.750000</td>\n",
       "      <td>3526.107910</td>\n",
       "      <td>3784.350098</td>\n",
       "      <td>918.745850</td>\n",
       "      <td>1404.800049</td>\n",
       "      <td>348.350006</td>\n",
       "      <td>2360.649902</td>\n",
       "      <td>2509.800049</td>\n",
       "      <td>591.099976</td>\n",
       "      <td>1343.550049</td>\n",
       "      <td>655.799988</td>\n",
       "      <td>1759.650024</td>\n",
       "      <td>16779.318359</td>\n",
       "      <td>1937.849976</td>\n",
       "      <td>28062.599609</td>\n",
       "      <td>3085.706299</td>\n",
       "      <td>940.750000</td>\n",
       "      <td>962.200012</td>\n",
       "      <td>1479.849976</td>\n",
       "      <td>480.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>2574.350098</td>\n",
       "      <td>4865.049805</td>\n",
       "      <td>10091.349609</td>\n",
       "      <td>3528.100342</td>\n",
       "      <td>3908.949951</td>\n",
       "      <td>918.795288</td>\n",
       "      <td>1438.699951</td>\n",
       "      <td>366.250000</td>\n",
       "      <td>2379.850098</td>\n",
       "      <td>2518.399902</td>\n",
       "      <td>598.750000</td>\n",
       "      <td>1348.500000</td>\n",
       "      <td>665.900024</td>\n",
       "      <td>1750.300049</td>\n",
       "      <td>16688.214844</td>\n",
       "      <td>1988.650024</td>\n",
       "      <td>28098.550781</td>\n",
       "      <td>3116.754150</td>\n",
       "      <td>977.750000</td>\n",
       "      <td>969.250000</td>\n",
       "      <td>1495.099976</td>\n",
       "      <td>485.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2614.550049</td>\n",
       "      <td>5280.899902</td>\n",
       "      <td>10489.299805</td>\n",
       "      <td>3465.881348</td>\n",
       "      <td>3882.600098</td>\n",
       "      <td>913.799988</td>\n",
       "      <td>1476.800049</td>\n",
       "      <td>362.600006</td>\n",
       "      <td>2406.550049</td>\n",
       "      <td>2577.000000</td>\n",
       "      <td>621.349976</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>662.650024</td>\n",
       "      <td>1811.449951</td>\n",
       "      <td>16543.800781</td>\n",
       "      <td>1997.300049</td>\n",
       "      <td>28687.550781</td>\n",
       "      <td>3108.892822</td>\n",
       "      <td>971.400024</td>\n",
       "      <td>977.400024</td>\n",
       "      <td>1508.849976</td>\n",
       "      <td>489.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2613.449951</td>\n",
       "      <td>5484.850098</td>\n",
       "      <td>11176.549805</td>\n",
       "      <td>3456.067871</td>\n",
       "      <td>3910.850098</td>\n",
       "      <td>909.549988</td>\n",
       "      <td>1472.500000</td>\n",
       "      <td>372.149994</td>\n",
       "      <td>2407.600098</td>\n",
       "      <td>2538.850098</td>\n",
       "      <td>621.450012</td>\n",
       "      <td>1356.349976</td>\n",
       "      <td>726.500000</td>\n",
       "      <td>1805.000000</td>\n",
       "      <td>16502.550781</td>\n",
       "      <td>2024.050049</td>\n",
       "      <td>28444.349609</td>\n",
       "      <td>3100.085693</td>\n",
       "      <td>1031.349976</td>\n",
       "      <td>976.900024</td>\n",
       "      <td>1506.800049</td>\n",
       "      <td>489.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>2536.399902</td>\n",
       "      <td>5451.899902</td>\n",
       "      <td>11041.650391</td>\n",
       "      <td>3436.241455</td>\n",
       "      <td>4062.350098</td>\n",
       "      <td>898.950012</td>\n",
       "      <td>1412.300049</td>\n",
       "      <td>364.399994</td>\n",
       "      <td>2353.750000</td>\n",
       "      <td>2420.100098</td>\n",
       "      <td>600.500000</td>\n",
       "      <td>1354.349976</td>\n",
       "      <td>717.849976</td>\n",
       "      <td>1748.800049</td>\n",
       "      <td>16309.250000</td>\n",
       "      <td>1994.500000</td>\n",
       "      <td>27910.500000</td>\n",
       "      <td>3020.873291</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>960.400024</td>\n",
       "      <td>1491.650024</td>\n",
       "      <td>492.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 22 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af7857a1-a1f9-42b4-99f5-ca7d69187520')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-af7857a1-a1f9-42b4-99f5-ca7d69187520 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-af7857a1-a1f9-42b4-99f5-ca7d69187520');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       ASIANPAINT   BAJFINANCE  ...        TITAN       WIPRO\n",
       "0      850.608887   602.348328  ...   340.842285  202.975677\n",
       "1      852.593201   598.059875  ...   340.212952  203.431641\n",
       "2      871.807617   592.664673  ...   336.630768  203.139801\n",
       "3      858.013977   603.474854  ...   336.776001  202.483200\n",
       "4      844.413879   603.380981  ...   333.096954  200.568176\n",
       "...           ...          ...  ...          ...         ...\n",
       "1309  2557.899902  4736.549805  ...  1479.849976  480.299988\n",
       "1310  2574.350098  4865.049805  ...  1495.099976  485.049988\n",
       "1311  2614.550049  5280.899902  ...  1508.849976  489.299988\n",
       "1312  2613.449951  5484.850098  ...  1506.800049  489.850006\n",
       "1313  2536.399902  5451.899902  ...  1491.650024  492.750000\n",
       "\n",
       "[1314 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pd.read_csv('n50.csv',parse_dates=['Date'],index_col='Date')\n",
    "x = x.loc[\"2016-01-01\" :]                         #Since 2016-01-01, 5y(1234rows till 2020-12-31), + year 2021's rows (till 30th of April)\n",
    "y=x.copy()                                        #deep copy\n",
    "x.reset_index(drop=True, inplace=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CxCrjuxxL3u",
    "outputId": "58edfbf8-4d88-4777-891b-5fda5818e1d9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stonks=[]\n",
    "for i in x:\n",
    "  stonks.append(i)\n",
    "len(stonks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "osDZsxPKxL3v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alldata=x   #the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lg57DjxzxL3w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#timesteps=60                                     #lstm hyperparameters \"Subject to be tuned\"\n",
    "#epoch=variable\n",
    "#batchSize=32\n",
    "#ineurons=175\n",
    "#hneurons=187\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5oVjazfVxL3w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=1):         # convert an array of values into a dataset matrix which will be used to train the lstm model.\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step):\n",
    "\t\ta = dataset[i:(i+time_step), 0]               #i=0, 0,1,2,3-----(timesteps-1)  -> timesteps\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yNQ0UH-_xL3x"
   },
   "outputs": [],
   "source": [
    "# Static parameters\n",
    "after2020=len(y.loc[\"2021-01-01\" : ])                    #number of days after 31-12-2020 \"automated\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xAz3b43kxL3x"
   },
   "outputs": [],
   "source": [
    "def stacked_lstm_model(df1,timesteps,batchSize,dropout_value,after2020):\n",
    "  scaler=MinMaxScaler(feature_range=(0,1))\n",
    "  df1=scaler.fit_transform(np.array(df1).reshape(-1,1))           #minmax scalar transformation of data\n",
    "  before_2021_data_length=int(len(df1)-after2020)                 #length of data before 2021\n",
    "  training_size=int(before_2021_data_length*0.80)                 #80% of training size, refered from Yadav et al (2020) (Science Direct)\n",
    "  train_data=df1[0:training_size,:]\n",
    "  test_data=df1[training_size:before_2021_data_length,:1]         #20% of testing data, refered from Yadav et al (2020) (Science Direct)\n",
    "  inpdata=df1[before_2021_data_length-timesteps:len(df1),:1]      #getting the data from 01-01-2021 onwards\n",
    "\n",
    "\n",
    "  #reshape into X=t,t+1,t+2,t+3,........t+\"timestep-1\" and Y=t+\"timestep\"\n",
    "  X_train, y_train = create_dataset(train_data, timesteps)\n",
    "  x_inp, y_inp = create_dataset(inpdata, timesteps)\n",
    "  x_test, y_test = create_dataset(test_data,timesteps)\n",
    "\n",
    "  X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "  x_inp = x_inp.reshape(x_inp.shape[0],x_inp.shape[1] , 1)        #reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "  x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1)\n",
    "\n",
    "  # initialising stacked lstm\n",
    "  model=Sequential()\n",
    "  model.add(LSTM(60,return_sequences=True,input_shape=(timesteps,1),activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(264,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(80,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(416,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(160,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(472,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(440,activation='tanh', dropout=0.1))\n",
    "  model.add(Dense(1,activation='sigmoid'))\n",
    "  model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "  model.fit(X_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=batchSize,verbose=1)     # training of the model\n",
    "\n",
    "  test_predict=model.predict(x_test)                    #prediction using test data as input\n",
    "\n",
    "  #performance metrics between, original test data and predicted test data\n",
    "  msetst =mean_squared_error(y_test,test_predict)\n",
    "  rmsetst=math.sqrt(msetst)\n",
    "  maetst =mean_absolute_error(y_test,test_predict)\n",
    "  r2tst  =r2_score(y_test,test_predict)\n",
    "  mapetst=mean_absolute_percentage_error(y_test,test_predict)\n",
    "  tstlst =[msetst,rmsetst,maetst,r2tst,mapetst]\n",
    "\n",
    "\n",
    "  #model is trained again on the test data so as to increase the learning (it is often termed as incremental learning)\n",
    "  #refered from url: https://www.justintodata.com/forecast-time-series-lstm-with-tensorflow-keras/#step-2-transforming-the-dataset-for-tensorflow-keras\n",
    "  #refered from url: https://github.com/keras-team/keras/issues/4446\n",
    "  model.fit(x_test,y_test,epochs=10,batch_size=batchSize,verbose=1)\n",
    "\n",
    "  out_predict=model.predict(x_inp)                      #dynamic prediction of the stock's closing price from 01-01-2021 onwards\n",
    "\n",
    "  #performance metrics between, original data(after 31-12-2020) and dynamically predicted data (after 31-12-2020)\n",
    "  mseinp =mean_squared_error(y_inp,out_predict)\n",
    "  rmseinp=math.sqrt(mseinp)\n",
    "  maeinp =mean_absolute_error(y_inp,out_predict)\n",
    "  r2inp  =r2_score(y_inp,out_predict)\n",
    "  mapeinp=mean_absolute_percentage_error(y_inp,out_predict)\n",
    "  inplst =[mseinp,rmseinp,maeinp,r2inp,mapeinp]\n",
    "\n",
    "\n",
    "  lst=[]\n",
    "  for i in out_predict:\n",
    "    lst.append(i)\n",
    "\n",
    "  p=train_data.tolist()\n",
    "  q=test_data.tolist()\n",
    "  p.extend(q)                                         #appending train and test data to make dataset before 2021 (data till 31-12-2020)\n",
    "  p.extend(lst)                                       #appending the data, forcasted from 01-01-2021 onwards, to the data till 31-12-2020\n",
    "  p=scaler.inverse_transform(p).tolist()\n",
    "\n",
    "  return rmseinp\n",
    "  #returns a dataframe, tstlst => test performance metrics, inplst => forcasted data performance metrics\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qWk9XTwPxL3z"
   },
   "outputs": [],
   "source": [
    "def stacked_lstm_tuning(timesteps, batchSize,dropout_value, after2020):\n",
    "    for i in alldata:                                   # this for loop will be iterated for each column of the original dataset\n",
    "      df1=alldata[i]\n",
    "      rmseinp=stacked_lstm_model(df1, timesteps, batchSize,dropout_value, after2020)    #hyperparameters are provided as input here\n",
    "    return rmseinp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ghCtNsSdxL30"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    timesteps=trial.suggest_int('timesteps',60,60)\n",
    "    batchSize=trial.suggest_int('batchSize',8,128,step=8)\n",
    "    dropout_value=trial.suggest_float('dropout_value',0.1,0.5) \n",
    "    return stacked_lstm_tuning(int(timesteps), int(batchSize), dropout_value, after2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ko3qlY6kxL31",
    "outputId": "e43dc112-d5ce-4a0d-ae47-710c7b3ba70c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-28 11:28:56,765]\u001b[0m A new study created in memory with name: no-name-1cc1e483-8c1f-4513-8182-8b4272c4b22f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 38s 661ms/step - loss: 0.0596 - val_loss: 0.3249\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0476 - val_loss: 0.1080\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.0169 - val_loss: 0.1430\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.0143 - val_loss: 0.1306\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.0135 - val_loss: 0.1230\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 237ms/step - loss: 0.0132 - val_loss: 0.1387\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0128 - val_loss: 0.1538\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 0.0130 - val_loss: 0.1362\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0130 - val_loss: 0.1322\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0131 - val_loss: 0.1216\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0998\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0277\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0626\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0613\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0342\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0238\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0334\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0332\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0248\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0221\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 653ms/step - loss: 0.0533 - val_loss: 0.0347\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0144 - val_loss: 0.0545\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0069 - val_loss: 0.0263\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0034 - val_loss: 0.0235\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0025 - val_loss: 0.0220\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0023 - val_loss: 0.0213\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0022 - val_loss: 0.0208\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0023 - val_loss: 0.0197\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0018 - val_loss: 0.0199\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0020 - val_loss: 0.0194\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0205\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0170\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0159\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 0.0121\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0104\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0287\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0348\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0235\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0196\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0142\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 21s 623ms/step - loss: 0.0436 - val_loss: 0.0204\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0222 - val_loss: 0.0258\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0097 - val_loss: 0.0206\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0062 - val_loss: 0.0191\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0044 - val_loss: 0.0214\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0037 - val_loss: 0.0190\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0037 - val_loss: 0.0167\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0031 - val_loss: 0.0154\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0030 - val_loss: 0.0147\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0033 - val_loss: 0.0149\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0151\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0127\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0118\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0109\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0102\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0082\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0078\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0082\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0073\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0077\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 631ms/step - loss: 0.0462 - val_loss: 0.0291\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0104 - val_loss: 0.0419\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0059 - val_loss: 0.0681\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0046 - val_loss: 0.0476\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0039 - val_loss: 0.0338\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0033 - val_loss: 0.0364\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0033 - val_loss: 0.0438\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0031 - val_loss: 0.0378\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0031 - val_loss: 0.0288\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0032 - val_loss: 0.0304\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.0218\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0193\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0194\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0131\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0144\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0113\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0106\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0072\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0085\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0056\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 619ms/step - loss: 0.0560 - val_loss: 0.4629\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0431 - val_loss: 0.4628\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0431 - val_loss: 0.4544\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0342 - val_loss: 0.4462\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0376 - val_loss: 0.4068\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0183 - val_loss: 0.2068\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0122 - val_loss: 0.2900\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0107 - val_loss: 0.2395\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0101 - val_loss: 0.2658\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0102 - val_loss: 0.2556\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.2399\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.1091\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0275\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0458\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0637\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0699\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0687\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0627\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0523\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0399\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 619ms/step - loss: 0.0533 - val_loss: 0.2850\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0339 - val_loss: 0.2850\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0339 - val_loss: 0.2850\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0339 - val_loss: 0.2850\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0339 - val_loss: 0.2850\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0339 - val_loss: 0.2849\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0307 - val_loss: 0.1448\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0250 - val_loss: 0.2628\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0169 - val_loss: 0.1120\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0097 - val_loss: 0.1736\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 231ms/step - loss: 0.1606\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0775\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0431\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0752\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0797\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0625\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0441\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0402\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0476\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0480\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 617ms/step - loss: 0.0424 - val_loss: 0.0180\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0333 - val_loss: 0.0497\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0172 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0060 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0035 - val_loss: 0.0168\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0025 - val_loss: 0.0123\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0020 - val_loss: 0.0096\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0019 - val_loss: 0.0100\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0019 - val_loss: 0.0107\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0017 - val_loss: 0.0103\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 0.0111\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0101\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0089\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0091\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0076\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0081\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0070\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0057\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0066\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0063\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 623ms/step - loss: 0.0186 - val_loss: 0.0156\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0159 - val_loss: 0.0207\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0194 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0164 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0150 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0040 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0033 - val_loss: 0.0094\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0026 - val_loss: 0.0080\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0080\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0081\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0073\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0066\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0066\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.0057\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0049\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0039\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0037\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0036\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 634ms/step - loss: 0.0699 - val_loss: 0.0114\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0352 - val_loss: 0.0786\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0103 - val_loss: 0.0760\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0059 - val_loss: 0.0298\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0038 - val_loss: 0.0330\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0026 - val_loss: 0.0127\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0024 - val_loss: 0.0154\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0023 - val_loss: 0.0200\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0023 - val_loss: 0.0165\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0022 - val_loss: 0.0157\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 233ms/step - loss: 0.0115\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0121\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0055\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0073\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0047\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.0059\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0041\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 0.0050\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0045\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0042\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 614ms/step - loss: 0.0359 - val_loss: 0.0250\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0274 - val_loss: 0.0249\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0225 - val_loss: 0.0229\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0063 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0048 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0038 - val_loss: 0.0124\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0033 - val_loss: 0.0116\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0029 - val_loss: 0.0122\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 260ms/step - loss: 0.0028 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0028 - val_loss: 0.0105\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.0110\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0095\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0093\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0088\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0079\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0076\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0066\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0072\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0067\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0057\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 619ms/step - loss: 0.0419 - val_loss: 0.0301\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0196 - val_loss: 0.0344\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0177 - val_loss: 0.0264\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0037 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0024 - val_loss: 0.0099\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 0.0025 - val_loss: 0.0108\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0022 - val_loss: 0.0088\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0021 - val_loss: 0.0082\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 230ms/step - loss: 0.0086\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0080\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0082\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0074\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0062\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0062\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0053\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0070\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0053\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 625ms/step - loss: 0.0557 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.2782\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.2782\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.2782\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.2782\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.2782\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.2782\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.2782\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.2782\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.2776\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.2267\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 641ms/step - loss: 0.0340 - val_loss: 0.0127\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 263ms/step - loss: 0.0010 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0010 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 9.1801e-04 - val_loss: 0.0031\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0029\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0024\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0029\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0026\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0018\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0014\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0020\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0016\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0014\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0013\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 650ms/step - loss: 0.0485 - val_loss: 0.0264\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0157 - val_loss: 0.0236\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0051 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0037 - val_loss: 0.0205\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0034 - val_loss: 0.0212\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0026 - val_loss: 0.0196\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0023 - val_loss: 0.0169\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0022 - val_loss: 0.0172\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0023 - val_loss: 0.0160\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0019 - val_loss: 0.0160\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 0.0164\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0158\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0161\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0121\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0144\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0095\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.0100\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0088\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0073\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0107\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 615ms/step - loss: 0.0569 - val_loss: 0.3681\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0249 - val_loss: 0.0087\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0099 - val_loss: 0.0169\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0046 - val_loss: 0.0636\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0026 - val_loss: 0.0255\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0020 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0019 - val_loss: 0.0097\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0018 - val_loss: 0.0189\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0019 - val_loss: 0.0201\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0017 - val_loss: 0.0164\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0141\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0146\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0041\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0063\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0049\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.0037\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0044\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0031\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0040\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 632ms/step - loss: 0.0516 - val_loss: 0.1316\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0250 - val_loss: 0.2689\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0165 - val_loss: 0.0488\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0073 - val_loss: 0.0399\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0036 - val_loss: 0.0698\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0026 - val_loss: 0.0862\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0020 - val_loss: 0.0625\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0016 - val_loss: 0.0566\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0017 - val_loss: 0.0399\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0015 - val_loss: 0.0451\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 0.0309\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0296\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0103\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0163\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.0080\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0087\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0097\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0064\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0071\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0058\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 613ms/step - loss: 0.0217 - val_loss: 0.0462\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0097 - val_loss: 0.0563\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0089 - val_loss: 0.0450\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0068 - val_loss: 0.0340\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0048 - val_loss: 0.0184\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0035 - val_loss: 0.0094\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0031 - val_loss: 0.0085\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0027 - val_loss: 0.0068\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0027 - val_loss: 0.0059\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 225ms/step - loss: 0.0066\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0055\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0047\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0044\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0041\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0043\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0056\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0040\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0046\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0039\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 647ms/step - loss: 0.0575 - val_loss: 0.1033\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0236 - val_loss: 0.0505\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0197 - val_loss: 0.1046\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0178 - val_loss: 0.0254\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0059 - val_loss: 0.0312\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0027 - val_loss: 0.0255\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0020 - val_loss: 0.0203\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0013 - val_loss: 0.0240\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0013 - val_loss: 0.0273\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 0.0013 - val_loss: 0.0273\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 225ms/step - loss: 0.0240\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0156\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0126\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0167\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0076\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0099\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0084\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0055\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0066\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0058\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 18s 637ms/step - loss: 0.0307 - val_loss: 0.0317\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0165 - val_loss: 0.0219\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0155 - val_loss: 0.0293\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0126 - val_loss: 0.0264\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0070 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0029 - val_loss: 0.0071\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0023 - val_loss: 0.0062\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.0062\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0063\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.0060\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0047\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 212ms/step - loss: 0.0052\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0048\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 0.0039\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0035\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0043\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0034\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 649ms/step - loss: 0.0597 - val_loss: 0.0842\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0275 - val_loss: 0.0725\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0238 - val_loss: 0.0388\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 0.0124 - val_loss: 0.0291\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0036 - val_loss: 0.0247\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0027 - val_loss: 0.0204\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 0.0025 - val_loss: 0.0212\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0024 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0023 - val_loss: 0.0190\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 227ms/step - loss: 0.0189\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0139\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0134\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0096\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0091\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0055\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0052\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0058\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0044\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0052\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 621ms/step - loss: 0.0659 - val_loss: 0.0278\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0356 - val_loss: 0.0491\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0150 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0053 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0044 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0036 - val_loss: 0.0111\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 247ms/step - loss: 0.0035 - val_loss: 0.0095\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0034 - val_loss: 0.0111\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 0.0032 - val_loss: 0.0091\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 237ms/step - loss: 0.0095\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0096\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0085\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0079\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0077\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.0067\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0070\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.0061\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0071\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0057\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 19s 657ms/step - loss: 0.0580 - val_loss: 0.1595\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 0.0407 - val_loss: 0.1595\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0404 - val_loss: 0.1197\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0134 - val_loss: 0.0751\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.0118 - val_loss: 0.0801\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.0106 - val_loss: 0.0783\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0104 - val_loss: 0.0684\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0098 - val_loss: 0.0717\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 240ms/step - loss: 0.0100 - val_loss: 0.0738\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.0100 - val_loss: 0.0718\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0642\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 0.0408\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.0571\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.0426\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0485\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0415\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 0.0393\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 0.0434\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.0399\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-28 11:50:50,597]\u001b[0m Trial 0 finished with value: 0.5277984472180897 and parameters: {'timesteps': 60, 'batchSize': 112, 'dropout_value': 0.3258134633862184}. Best is trial 0 with value: 0.5277984472180897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 526ms/step - loss: 0.0578 - val_loss: 0.3250\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 0.0479 - val_loss: 0.0944\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0182 - val_loss: 0.1348\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0134 - val_loss: 0.1307\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0131 - val_loss: 0.1413\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0128 - val_loss: 0.1395\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0129 - val_loss: 0.1428\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0127 - val_loss: 0.1509\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0127 - val_loss: 0.1393\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0128 - val_loss: 0.1540\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.1208\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0389\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0676\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0376\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0242\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0372\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0268\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0228\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0267\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0258\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 537ms/step - loss: 0.0600 - val_loss: 0.0500\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0358 - val_loss: 0.0474\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0080 - val_loss: 0.0260\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0052 - val_loss: 0.0285\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0027 - val_loss: 0.0230\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0023 - val_loss: 0.0222\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0019 - val_loss: 0.0212\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0019 - val_loss: 0.0198\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0020 - val_loss: 0.0191\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0017 - val_loss: 0.0185\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.0187\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0170\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0145\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0113\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0114\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0144\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0074\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0076\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0085\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0069\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 23s 923ms/step - loss: 0.0450 - val_loss: 0.0217\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 0.0221 - val_loss: 0.0249\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.0050 - val_loss: 0.0216\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 0.0039 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.0034 - val_loss: 0.0183\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 0.0034 - val_loss: 0.0161\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.0032 - val_loss: 0.0151\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0031 - val_loss: 0.0142\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0032 - val_loss: 0.0138\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0036 - val_loss: 0.0122\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0135\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0122\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0125\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0133\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0120\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0104\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0094\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0090\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0073\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0079\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 550ms/step - loss: 0.0477 - val_loss: 0.1249\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0224 - val_loss: 0.1243\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0060 - val_loss: 0.0397\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0040 - val_loss: 0.0555\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0040 - val_loss: 0.0406\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0035 - val_loss: 0.0386\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0033 - val_loss: 0.0400\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0031 - val_loss: 0.0365\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0029 - val_loss: 0.0332\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0031 - val_loss: 0.0309\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0181\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0219\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0118\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0103\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0068\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0065\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0071\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0041\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0043\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0061\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 20s 535ms/step - loss: 0.0523 - val_loss: 0.4628\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0431 - val_loss: 0.4577\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0194 - val_loss: 0.2138\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0113 - val_loss: 0.2708\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0106 - val_loss: 0.2809\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0105 - val_loss: 0.2611\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0104 - val_loss: 0.2922\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0101 - val_loss: 0.2611\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0099 - val_loss: 0.2713\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0104 - val_loss: 0.2790\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.2216\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0361\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0718\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0701\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0531\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0299\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0231\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0313\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0288\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0231\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 533ms/step - loss: 0.0495 - val_loss: 0.2850\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0339 - val_loss: 0.2850\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0339 - val_loss: 0.2850\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0339 - val_loss: 0.2849\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0228 - val_loss: 0.1233\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0083 - val_loss: 0.1682\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0078 - val_loss: 0.1564\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0076 - val_loss: 0.1501\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0077 - val_loss: 0.1471\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0076 - val_loss: 0.1517\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.1167\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0836\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0678\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.0482\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0542\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0410\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0446\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0432\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0395\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0409\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 522ms/step - loss: 0.0401 - val_loss: 0.0415\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0184 - val_loss: 0.0138\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0044 - val_loss: 0.0116\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0035 - val_loss: 0.0165\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0028 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0022 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0019 - val_loss: 0.0103\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0019 - val_loss: 0.0113\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0018 - val_loss: 0.0089\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0017 - val_loss: 0.0121\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.0111\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0124\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0105\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0100\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0088\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0076\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0074\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0072\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0061\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0062\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 533ms/step - loss: 0.0194 - val_loss: 0.0197\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0168 - val_loss: 0.0178\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0133 - val_loss: 0.0175\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0030 - val_loss: 0.0106\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0027 - val_loss: 0.0079\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0025 - val_loss: 0.0075\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.0073\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0067\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0065\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0061\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0054\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0065\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0061\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0062\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0040\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0045\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 533ms/step - loss: 0.0478 - val_loss: 0.0350\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0273 - val_loss: 0.0227\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0063 - val_loss: 0.0273\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0037 - val_loss: 0.0329\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0029 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0024 - val_loss: 0.0201\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0022 - val_loss: 0.0167\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0022 - val_loss: 0.0217\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0022 - val_loss: 0.0162\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0021 - val_loss: 0.0168\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 0.0141\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0069\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0056\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0045\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0057\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0047\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0045\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0048\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0041\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0048\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 549ms/step - loss: 0.0367 - val_loss: 0.0250\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0206 - val_loss: 0.0199\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0088 - val_loss: 0.0132\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0034 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0029 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0029 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0030 - val_loss: 0.0098\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0031 - val_loss: 0.0115\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0031 - val_loss: 0.0086\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0027 - val_loss: 0.0090\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.0093\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0099\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0093\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0082\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0064\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0100\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0113\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0083\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0066\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0074\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 528ms/step - loss: 0.0436 - val_loss: 0.0627\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0244 - val_loss: 0.0533\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0217 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0149 - val_loss: 0.0218\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0053 - val_loss: 0.0142\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0040 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0025 - val_loss: 0.0100\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0025 - val_loss: 0.0092\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0023 - val_loss: 0.0088\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0021 - val_loss: 0.0086\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.0092\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0079\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0078\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0072\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0064\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0056\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0060\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0063\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0068\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0049\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 545ms/step - loss: 0.0543 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0354 - val_loss: 0.2776\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0204 - val_loss: 0.1569\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0123 - val_loss: 0.1732\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0121 - val_loss: 0.1583\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0122 - val_loss: 0.1432\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0122 - val_loss: 0.1674\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0124 - val_loss: 0.1570\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 0.1174\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0772\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0572\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0400\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0430\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0349\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0386\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0361\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0345\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0349\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 538ms/step - loss: 0.0304 - val_loss: 0.0129\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 228ms/step - loss: 0.0087 - val_loss: 0.0637\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0174 - val_loss: 0.0153\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0102 - val_loss: 0.0149\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0096 - val_loss: 0.0133\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0102 - val_loss: 0.0175\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0098 - val_loss: 0.0135\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0132\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0123\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0122\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0128\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0126\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0128\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0118\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0115\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0104\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0109\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 559ms/step - loss: 0.0457 - val_loss: 0.0708\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0177 - val_loss: 0.0422\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0059 - val_loss: 0.0307\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0038 - val_loss: 0.0255\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0033 - val_loss: 0.0238\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0028 - val_loss: 0.0193\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0023 - val_loss: 0.0177\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0019 - val_loss: 0.0176\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0022 - val_loss: 0.0177\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0020 - val_loss: 0.0160\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.0168\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0166\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0112\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0164\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0158\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0140\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0193\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0156\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0095\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0081\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 532ms/step - loss: 0.0525 - val_loss: 0.0108\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 0.0149 - val_loss: 0.0783\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0052 - val_loss: 0.0171\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0029 - val_loss: 0.0223\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0021 - val_loss: 0.0256\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0018 - val_loss: 0.0154\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0018 - val_loss: 0.0114\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0018 - val_loss: 0.0144\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0018 - val_loss: 0.0135\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 0.0018 - val_loss: 0.0188\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0159\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0097\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0060\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0048\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0033\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0030\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0032\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0032\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0030\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0032\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 532ms/step - loss: 0.0595 - val_loss: 0.3821\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 228ms/step - loss: 0.0264 - val_loss: 0.2248\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0125 - val_loss: 0.1007\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0042 - val_loss: 0.0968\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0026 - val_loss: 0.0537\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0019 - val_loss: 0.0348\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0016 - val_loss: 0.0397\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0016 - val_loss: 0.0487\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0015 - val_loss: 0.0433\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0016 - val_loss: 0.0368\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0219\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0168\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0138\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0126\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0083\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0081\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0071\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0070\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0062\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0048\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 535ms/step - loss: 0.0186 - val_loss: 0.0323\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0092 - val_loss: 0.0358\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0081 - val_loss: 0.0336\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0072 - val_loss: 0.0266\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0052 - val_loss: 0.0214\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0034 - val_loss: 0.0113\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0029 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0027 - val_loss: 0.0076\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0028 - val_loss: 0.0064\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0085\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0047\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0058\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0043\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0062\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0067\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0045\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0049\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0054\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0045\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 538ms/step - loss: 0.0434 - val_loss: 0.0920\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0262 - val_loss: 0.1011\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0105 - val_loss: 0.0346\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0046 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0038 - val_loss: 0.0277\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0019 - val_loss: 0.0213\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0014 - val_loss: 0.0245\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0013 - val_loss: 0.0240\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0013 - val_loss: 0.0277\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0013 - val_loss: 0.0241\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0189\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0182\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0164\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0107\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0100\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0058\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0064\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0040\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0044\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0033\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 539ms/step - loss: 0.0305 - val_loss: 0.0372\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0171 - val_loss: 0.0277\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0164 - val_loss: 0.0351\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0165 - val_loss: 0.0226\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0078 - val_loss: 0.0145\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0033 - val_loss: 0.0113\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0027 - val_loss: 0.0080\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0065\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0055\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0068\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0064\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0045\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0038\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0029\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0055\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0055\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0042\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 535ms/step - loss: 0.0445 - val_loss: 0.0692\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0126 - val_loss: 0.0184\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0041 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0028 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0024 - val_loss: 0.0170\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0025 - val_loss: 0.0176\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0023 - val_loss: 0.0153\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0022 - val_loss: 0.0147\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0025 - val_loss: 0.0146\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0104\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0129\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0068\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0064\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0072\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0069\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0072\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0077\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0069\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0031\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 525ms/step - loss: 0.0520 - val_loss: 0.0288\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0084 - val_loss: 0.0186\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0050 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 230ms/step - loss: 0.0039 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0036 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0035 - val_loss: 0.0118\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0034 - val_loss: 0.0096\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 0.0033 - val_loss: 0.0091\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0030 - val_loss: 0.0090\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0031 - val_loss: 0.0083\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0083\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0093\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0083\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0090\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.0117\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0085\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0072\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0069\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0070\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0070\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 543ms/step - loss: 0.0545 - val_loss: 0.1585\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0233 - val_loss: 0.0582\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 230ms/step - loss: 0.0115 - val_loss: 0.0577\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0100 - val_loss: 0.0689\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0098 - val_loss: 0.0664\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0098 - val_loss: 0.0676\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 0.0098 - val_loss: 0.0729\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0100 - val_loss: 0.0726\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0100 - val_loss: 0.0625\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 0.0098 - val_loss: 0.0717\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.0607\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0670\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0394\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0485\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0386\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0440\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0390\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0415\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0401\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-28 12:13:13,644]\u001b[0m Trial 1 finished with value: 0.46070315379231375 and parameters: {'timesteps': 60, 'batchSize': 88, 'dropout_value': 0.3739823090930936}. Best is trial 1 with value: 0.46070315379231375.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lstm_parameter_selection=optuna.create_study(direction='minimize')\n",
    "lstm_parameter_selection.optimize(objective,n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xT5m6_EbxL31",
    "outputId": "4830c3af-7677-46d1-ad2c-334d7f7ffedf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batchSize': 88, 'dropout_value': 0.3739823090930936, 'timesteps': 60}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best=lstm_parameter_selection.best_params\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PB1zLhd3xL32"
   },
   "outputs": [],
   "source": [
    "timesteps=best['timesteps']\n",
    "batchSize=best['batchSize']\n",
    "dropout_value=best['dropout_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IISZYXxOxL32",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stacked_lstm_forecast(df1, timesteps, batchSize, after2020):\n",
    "  scaler=MinMaxScaler(feature_range=(0,1))\n",
    "  df1=scaler.fit_transform(np.array(df1).reshape(-1,1))           #minmax scalar transformation of data\n",
    "\n",
    "  before_2021_data_length=int(len(df1)-after2020)                 #length of data before 2021\n",
    "  training_size=int(before_2021_data_length*0.80)                 #80% of training size, refered from Yadav et al (2020) (Science Direct)\n",
    "  train_data=df1[0:training_size,:]\n",
    "  test_data=df1[training_size:before_2021_data_length,:1]         #20% of testing data, refered from Yadav et al (2020) (Science Direct)\n",
    "  inpdata=df1[before_2021_data_length-timesteps:len(df1),:1]      #getting the data from 01-01-2021 onwards\n",
    "\n",
    "\n",
    "  #reshape into X=t,t+1,t+2,t+3,........t+\"timestep-1\" and Y=t+\"timestep\"\n",
    "  X_train, y_train = create_dataset(train_data, timesteps)\n",
    "  x_inp, y_inp = create_dataset(inpdata, timesteps)\n",
    "  x_test, y_test = create_dataset(test_data,timesteps)\n",
    "\n",
    "  X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "  x_inp = x_inp.reshape(x_inp.shape[0],x_inp.shape[1] , 1)        #reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "  x_test = x_test.reshape(x_test.shape[0],x_test.shape[1] , 1)\n",
    "\n",
    "  # initialising stacked lstm\n",
    "  model=Sequential()\n",
    "    #input layer\n",
    "  model.add(LSTM(60,return_sequences=True,input_shape=(timesteps,1),activation='tanh', dropout=0.1))\n",
    "    #hidden layers\n",
    "  model.add(LSTM(264,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(80,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(416,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(160,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(472,return_sequences=True,activation='tanh', dropout=0.1))\n",
    "  model.add(LSTM(440,activation='tanh', dropout=0.1))\n",
    "    #dense layer\n",
    "  model.add(Dense(1,activation='sigmoid'))\n",
    "  model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "  model.fit(X_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=batchSize,verbose=1)     # training of the model\n",
    "\n",
    "  test_predict=model.predict(x_test)                    #prediction using test data as input\n",
    "\n",
    "  #performance metrics between, original test data and predicted test data\n",
    "  msetst =mean_squared_error(y_test,test_predict)\n",
    "  rmsetst=math.sqrt(msetst)\n",
    "  maetst =mean_absolute_error(y_test,test_predict)\n",
    "  r2tst  =r2_score(y_test,test_predict)\n",
    "  mapetst=mean_absolute_percentage_error(y_test,test_predict)\n",
    "  tstlst =[msetst,rmsetst,maetst,r2tst,mapetst]\n",
    "\n",
    "\n",
    "  #model is trained again on the test data so as to increase the learning (it is often termed as incremental learning)\n",
    "  #refered from url: https://www.justintodata.com/forecast-time-series-lstm-with-tensorflow-keras/#step-2-transforming-the-dataset-for-tensorflow-keras\n",
    "  #refered from url: https://github.com/keras-team/keras/issues/4446\n",
    "  model.fit(x_test,y_test,epochs=10,batch_size=batchSize,verbose=1)\n",
    "\n",
    "  out_predict=model.predict(x_inp)                      #dynamic prediction of the stock's closing price from 01-01-2021 onwards\n",
    "\n",
    "  #performance metrics between, original data(after 31-12-2020) and dynamically predicted data (after 31-12-2020)\n",
    "  mseinp =mean_squared_error(y_inp,out_predict)\n",
    "  rmseinp=math.sqrt(mseinp)\n",
    "  maeinp =mean_absolute_error(y_inp,out_predict)\n",
    "  r2inp  =r2_score(y_inp,out_predict)\n",
    "  mapeinp=mean_absolute_percentage_error(y_inp,out_predict)\n",
    "  inplst =[mseinp,rmseinp,maeinp,r2inp,mapeinp]\n",
    "\n",
    "    #more metrics\n",
    "\n",
    "\n",
    "  lst=[]\n",
    "  for i in out_predict:\n",
    "    lst.append(i)\n",
    "\n",
    "  p=train_data.tolist()\n",
    "  q=test_data.tolist()\n",
    "  p.extend(q)                                         #appending train and test data to make dataset before 2021 (data till 31-12-2020)\n",
    "  p.extend(lst)                                       #appending the data, forcasted from 01-01-2021 onwards, to the data till 31-12-2020\n",
    "  p=scaler.inverse_transform(p).tolist()\n",
    "\n",
    "  return pd.DataFrame(p), tstlst, inplst\n",
    "  #returns a dataframe, tstlst => test performance metrics, inplst => forcasted data performance metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bge56W7RxL33",
    "outputId": "eeff2bbb-ccf8-4fed-abba-1138e5823d0d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 539ms/step - loss: 0.0604 - val_loss: 0.3248\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0455 - val_loss: 0.2636\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0393 - val_loss: 0.2057\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0158 - val_loss: 0.1718\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0139 - val_loss: 0.1271\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0129 - val_loss: 0.1472\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0130 - val_loss: 0.1554\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0129 - val_loss: 0.1397\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0128 - val_loss: 0.1363\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 0.0128 - val_loss: 0.1445\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.1251\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0281\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0668\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0617\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0303\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0265\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0313\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0245\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0226\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0235\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 532ms/step - loss: 0.0435 - val_loss: 0.1713\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0207 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0050 - val_loss: 0.0325\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0036 - val_loss: 0.0230\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0023 - val_loss: 0.0224\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0022 - val_loss: 0.0212\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0019 - val_loss: 0.0197\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0021 - val_loss: 0.0185\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0018 - val_loss: 0.0173\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0018 - val_loss: 0.0169\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 0.0168\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0160\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0139\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0094\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0105\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0085\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0102\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0075\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0087\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0088\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 544ms/step - loss: 0.0460 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0183 - val_loss: 0.0221\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0064 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0042 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0035 - val_loss: 0.0194\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0034 - val_loss: 0.0155\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0032 - val_loss: 0.0162\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0032 - val_loss: 0.0137\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0030 - val_loss: 0.0133\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0031 - val_loss: 0.0118\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0122\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0106\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0093\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0093\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0099\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0085\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0080\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0070\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0060\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0062\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 530ms/step - loss: 0.0574 - val_loss: 0.0233\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0119 - val_loss: 0.0313\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0051 - val_loss: 0.0373\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0038 - val_loss: 0.0264\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0032 - val_loss: 0.0353\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0029 - val_loss: 0.0339\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 0.0031 - val_loss: 0.0271\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0029 - val_loss: 0.0295\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0029 - val_loss: 0.0311\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0028 - val_loss: 0.0238\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0149\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0170\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0107\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0071\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0093\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0075\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0081\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0061\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0046\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0043\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 523ms/step - loss: 0.0543 - val_loss: 0.4617\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0352 - val_loss: 0.4310\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0243 - val_loss: 0.1779\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0129 - val_loss: 0.2791\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0106 - val_loss: 0.2726\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0103 - val_loss: 0.2395\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0100 - val_loss: 0.2570\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0100 - val_loss: 0.2563\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0099 - val_loss: 0.2562\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0102 - val_loss: 0.2359\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.1982\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0283\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0648\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0716\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0596\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0379\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0244\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0262\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0238\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0224\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 528ms/step - loss: 0.0489 - val_loss: 0.1585\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0080 - val_loss: 0.1204\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0082 - val_loss: 0.0895\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0060 - val_loss: 0.1398\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0025 - val_loss: 0.0851\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0018 - val_loss: 0.0912\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0014 - val_loss: 0.0957\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0013 - val_loss: 0.0837\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0012 - val_loss: 0.0795\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0012 - val_loss: 0.0596\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 0.0586\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0425\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0306\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0205\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0106\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0104\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0085\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0130\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0086\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0059\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 536ms/step - loss: 0.0425 - val_loss: 0.0259\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0283 - val_loss: 0.0126\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0025 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0021 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0018 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0016 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0017 - val_loss: 0.0101\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0017 - val_loss: 0.0099\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0016 - val_loss: 0.0090\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.0091\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0087\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0087\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0080\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0087\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0080\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0078\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0149\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0086\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0108\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 514ms/step - loss: 0.0179 - val_loss: 0.0170\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0196 - val_loss: 0.0218\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0040 - val_loss: 0.0084\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0029 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0026 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 0.0064\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0065\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0113\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0094\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0078\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0049\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0038\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0056\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0044\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0037\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 529ms/step - loss: 0.0596 - val_loss: 0.0633\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 3s 226ms/step - loss: 0.0150 - val_loss: 0.0174\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0046 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0034 - val_loss: 0.0238\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0029 - val_loss: 0.0177\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0025 - val_loss: 0.0174\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0024 - val_loss: 0.0208\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0023 - val_loss: 0.0132\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0023 - val_loss: 0.0148\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0023 - val_loss: 0.0163\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0112\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0076\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0075\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0062\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0045\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0052\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0041\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0045\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0043\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0042\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 532ms/step - loss: 0.0347 - val_loss: 0.0397\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0287 - val_loss: 0.0334\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 0.0131 - val_loss: 0.0157\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 0.0052 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0039 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0031 - val_loss: 0.0115\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0029 - val_loss: 0.0109\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0026 - val_loss: 0.0106\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0026 - val_loss: 0.0101\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0028 - val_loss: 0.0093\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0107\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0110\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0104\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0106\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0102\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0094\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0115\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0105\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0084\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0066\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 554ms/step - loss: 0.0359 - val_loss: 0.0221\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0217 - val_loss: 0.0389\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0063 - val_loss: 0.0113\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0036 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0024 - val_loss: 0.0117\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0023 - val_loss: 0.0105\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0023 - val_loss: 0.0098\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0022 - val_loss: 0.0095\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0104\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0083\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0081\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0076\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0064\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0051\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0059\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0062\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0080\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0069\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 511ms/step - loss: 0.0553 - val_loss: 0.2782\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0354 - val_loss: 0.2782\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0327 - val_loss: 0.1368\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0136 - val_loss: 0.1247\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0126 - val_loss: 0.1172\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0132 - val_loss: 0.1298\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0129 - val_loss: 0.1286\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0123 - val_loss: 0.1282\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0127 - val_loss: 0.1348\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.1098\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0517\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0593\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0342\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0453\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0413\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0349\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0351\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0351\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0345\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 525ms/step - loss: 0.0554 - val_loss: 0.0922\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0409 - val_loss: 0.0194\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0130 - val_loss: 0.0227\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0102 - val_loss: 0.0148\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0100 - val_loss: 0.0141\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0140\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0129\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0127\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0127\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0127\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0126\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0125\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0127\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0126\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0128\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 520ms/step - loss: 0.0477 - val_loss: 0.0789\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 224ms/step - loss: 0.0364 - val_loss: 0.0678\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0148 - val_loss: 0.0364\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0045 - val_loss: 0.0276\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0028 - val_loss: 0.0242\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0026 - val_loss: 0.0211\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0026 - val_loss: 0.0208\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0022 - val_loss: 0.0194\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0023 - val_loss: 0.0186\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0021 - val_loss: 0.0181\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.0190\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0165\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0180\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0145\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0123\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0143\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0140\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0118\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0115\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0102\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 542ms/step - loss: 0.0459 - val_loss: 0.2170\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0135 - val_loss: 0.0037\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0052 - val_loss: 0.0399\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0027 - val_loss: 0.0260\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0022 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0020 - val_loss: 0.0104\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0018 - val_loss: 0.0114\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0017 - val_loss: 0.0151\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0017 - val_loss: 0.0124\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0015 - val_loss: 0.0087\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0182\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0238\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0238\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0238\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0238\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0238\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0238\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0237\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0236\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0208\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 519ms/step - loss: 0.0545 - val_loss: 0.0835\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0453 - val_loss: 0.2701\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0115 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0032 - val_loss: 0.0578\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0022 - val_loss: 0.0438\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0018 - val_loss: 0.0463\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0017 - val_loss: 0.0434\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0015 - val_loss: 0.0497\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0015 - val_loss: 0.0402\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0016 - val_loss: 0.0469\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0302\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0106\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0091\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0090\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0097\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0079\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0065\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0063\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0051\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0053\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 522ms/step - loss: 0.0163 - val_loss: 0.0324\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0088 - val_loss: 0.0392\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0097 - val_loss: 0.0358\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0093 - val_loss: 0.0517\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0089 - val_loss: 0.0486\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0082 - val_loss: 0.0458\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0058 - val_loss: 0.0114\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0042 - val_loss: 0.0173\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0037 - val_loss: 0.0108\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0030 - val_loss: 0.0080\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.0101\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0088\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0060\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0062\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0059\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0056\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0059\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0052\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0058\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0050\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 515ms/step - loss: 0.0783 - val_loss: 0.0222\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0537 - val_loss: 0.0958\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0328 - val_loss: 0.1497\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0297 - val_loss: 0.1518\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0295 - val_loss: 0.1338\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0293 - val_loss: 0.1331\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0293 - val_loss: 0.1445\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0296 - val_loss: 0.1204\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0297 - val_loss: 0.1297\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0301 - val_loss: 0.1651\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 0.1406\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0247\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0631\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0558\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0271\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0247\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0294\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0234\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0214\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0237\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 513ms/step - loss: 0.0295 - val_loss: 0.0258\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0078 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0026 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0027 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.0046\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0038\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0038\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0032\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0035\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0058\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0047\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0043\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0038\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0060\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 523ms/step - loss: 0.0501 - val_loss: 0.0623\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0289 - val_loss: 0.0658\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0103 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0054 - val_loss: 0.0239\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0037 - val_loss: 0.0182\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0030 - val_loss: 0.0168\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0025 - val_loss: 0.0164\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0023 - val_loss: 0.0172\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0021 - val_loss: 0.0151\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0021 - val_loss: 0.0142\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.0130\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0086\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0069\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0053\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0050\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0044\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0055\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0044\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0059\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0038\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 18s 547ms/step - loss: 0.0484 - val_loss: 0.0186\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0095 - val_loss: 0.0296\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0055 - val_loss: 0.0180\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0047 - val_loss: 0.0100\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0037 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0036 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0031 - val_loss: 0.0079\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0032 - val_loss: 0.0085\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 228ms/step - loss: 0.0029 - val_loss: 0.0084\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0078\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0076\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0065\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0061\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0066\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0058\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0071\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0060\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0068\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0056\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 19s 549ms/step - loss: 0.0513 - val_loss: 0.1595\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 225ms/step - loss: 0.0402 - val_loss: 0.0997\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0257 - val_loss: 0.0862\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0139 - val_loss: 0.0982\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0112 - val_loss: 0.0674\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 3s 230ms/step - loss: 0.0099 - val_loss: 0.0646\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 229ms/step - loss: 0.0099 - val_loss: 0.0657\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 226ms/step - loss: 0.0100 - val_loss: 0.0750\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0099 - val_loss: 0.0676\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 227ms/step - loss: 0.0100 - val_loss: 0.0611\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0560\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0430\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0434\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0471\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 0.0465\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0390\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 173ms/step - loss: 0.0461\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0386\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 0.0459\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0441\n"
     ]
    }
   ],
   "source": [
    "mtest=[]\n",
    "mdynamic=[]\n",
    "fdata=pd.DataFrame()\n",
    "for i in alldata:                                   # this for loop will be for each column of the original dataset\n",
    "  temp=alldata[i]\n",
    "  ftemp,trmse,drmse=stacked_lstm_forecast(temp, timesteps, batchSize, after2020)    #hyperparameters are provided as input here\n",
    "  fdata = pd.concat([fdata,ftemp],axis = 1)\n",
    "  mtest.append(trmse)\n",
    "  mdynamic.append(drmse)\n",
    "fdata.columns=stonks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "2ygDfD-txL34",
    "outputId": "89a5317f-ed54-48f8-a740-dd3a3b39290d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5084ad7f-2a29-485c-b3db-f1b8a7d07a12\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>HDFCBANK</th>\n",
       "      <th>HINDALCO</th>\n",
       "      <th>HINDUNILVR</th>\n",
       "      <th>HDFC</th>\n",
       "      <th>ICICIBANK</th>\n",
       "      <th>INFY</th>\n",
       "      <th>JSWSTEEL</th>\n",
       "      <th>KOTAKBANK</th>\n",
       "      <th>NESTLEIND</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>WIPRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>850.608887</td>\n",
       "      <td>602.348328</td>\n",
       "      <td>1978.543457</td>\n",
       "      <td>1374.428223</td>\n",
       "      <td>1108.503052</td>\n",
       "      <td>385.106506</td>\n",
       "      <td>528.506653</td>\n",
       "      <td>82.550529</td>\n",
       "      <td>792.340698</td>\n",
       "      <td>1169.114624</td>\n",
       "      <td>227.737686</td>\n",
       "      <td>482.005096</td>\n",
       "      <td>93.927940</td>\n",
       "      <td>725.564270</td>\n",
       "      <td>5311.719238</td>\n",
       "      <td>486.556549</td>\n",
       "      <td>11121.029297</td>\n",
       "      <td>1082.013306</td>\n",
       "      <td>219.908173</td>\n",
       "      <td>461.389832</td>\n",
       "      <td>340.842285</td>\n",
       "      <td>202.975677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852.593201</td>\n",
       "      <td>598.059875</td>\n",
       "      <td>1954.307739</td>\n",
       "      <td>1368.077148</td>\n",
       "      <td>1096.297607</td>\n",
       "      <td>385.152100</td>\n",
       "      <td>519.647644</td>\n",
       "      <td>78.515373</td>\n",
       "      <td>794.607056</td>\n",
       "      <td>1130.328369</td>\n",
       "      <td>221.286560</td>\n",
       "      <td>470.513763</td>\n",
       "      <td>95.546753</td>\n",
       "      <td>703.665161</td>\n",
       "      <td>5205.810547</td>\n",
       "      <td>476.948639</td>\n",
       "      <td>10804.255859</td>\n",
       "      <td>1061.057739</td>\n",
       "      <td>219.481003</td>\n",
       "      <td>458.151581</td>\n",
       "      <td>340.212952</td>\n",
       "      <td>203.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>871.807617</td>\n",
       "      <td>592.664673</td>\n",
       "      <td>1940.843384</td>\n",
       "      <td>1365.361816</td>\n",
       "      <td>1094.199951</td>\n",
       "      <td>383.717926</td>\n",
       "      <td>515.715759</td>\n",
       "      <td>80.314178</td>\n",
       "      <td>784.385376</td>\n",
       "      <td>1123.546631</td>\n",
       "      <td>222.282349</td>\n",
       "      <td>468.398560</td>\n",
       "      <td>99.058762</td>\n",
       "      <td>706.109497</td>\n",
       "      <td>5199.016113</td>\n",
       "      <td>481.668732</td>\n",
       "      <td>10867.756836</td>\n",
       "      <td>1051.810791</td>\n",
       "      <td>234.346603</td>\n",
       "      <td>463.031219</td>\n",
       "      <td>336.630768</td>\n",
       "      <td>203.139801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858.013977</td>\n",
       "      <td>603.474854</td>\n",
       "      <td>1933.413330</td>\n",
       "      <td>1381.469727</td>\n",
       "      <td>1084.378296</td>\n",
       "      <td>383.080475</td>\n",
       "      <td>517.997192</td>\n",
       "      <td>78.320908</td>\n",
       "      <td>779.852783</td>\n",
       "      <td>1123.453613</td>\n",
       "      <td>216.567245</td>\n",
       "      <td>466.348938</td>\n",
       "      <td>96.781441</td>\n",
       "      <td>701.969116</td>\n",
       "      <td>5251.443359</td>\n",
       "      <td>494.631134</td>\n",
       "      <td>11188.242188</td>\n",
       "      <td>1066.431152</td>\n",
       "      <td>229.604980</td>\n",
       "      <td>465.870178</td>\n",
       "      <td>336.776001</td>\n",
       "      <td>202.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>844.413879</td>\n",
       "      <td>603.380981</td>\n",
       "      <td>1921.943726</td>\n",
       "      <td>1356.088257</td>\n",
       "      <td>1074.604370</td>\n",
       "      <td>375.636505</td>\n",
       "      <td>512.706055</td>\n",
       "      <td>74.528839</td>\n",
       "      <td>758.761841</td>\n",
       "      <td>1095.722656</td>\n",
       "      <td>213.666412</td>\n",
       "      <td>458.259216</td>\n",
       "      <td>93.868484</td>\n",
       "      <td>690.046875</td>\n",
       "      <td>5177.484863</td>\n",
       "      <td>485.550232</td>\n",
       "      <td>10725.758789</td>\n",
       "      <td>1061.796509</td>\n",
       "      <td>213.500595</td>\n",
       "      <td>453.183197</td>\n",
       "      <td>333.096954</td>\n",
       "      <td>200.568176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1992.027309</td>\n",
       "      <td>4359.514840</td>\n",
       "      <td>8030.867508</td>\n",
       "      <td>3647.680712</td>\n",
       "      <td>2982.166900</td>\n",
       "      <td>835.693480</td>\n",
       "      <td>1273.295731</td>\n",
       "      <td>299.268587</td>\n",
       "      <td>2169.137736</td>\n",
       "      <td>2535.434876</td>\n",
       "      <td>522.920595</td>\n",
       "      <td>914.055420</td>\n",
       "      <td>254.421819</td>\n",
       "      <td>1749.541220</td>\n",
       "      <td>12703.259742</td>\n",
       "      <td>2132.065204</td>\n",
       "      <td>23386.142760</td>\n",
       "      <td>2438.488582</td>\n",
       "      <td>757.872556</td>\n",
       "      <td>957.371198</td>\n",
       "      <td>1522.641586</td>\n",
       "      <td>278.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1992.027309</td>\n",
       "      <td>4313.668901</td>\n",
       "      <td>8056.330126</td>\n",
       "      <td>3651.359006</td>\n",
       "      <td>2982.166900</td>\n",
       "      <td>835.695322</td>\n",
       "      <td>1270.600932</td>\n",
       "      <td>300.186210</td>\n",
       "      <td>2169.268341</td>\n",
       "      <td>2534.201464</td>\n",
       "      <td>522.268603</td>\n",
       "      <td>914.055420</td>\n",
       "      <td>254.423776</td>\n",
       "      <td>1745.401071</td>\n",
       "      <td>12703.266434</td>\n",
       "      <td>2129.538565</td>\n",
       "      <td>23427.048720</td>\n",
       "      <td>2438.488862</td>\n",
       "      <td>762.549190</td>\n",
       "      <td>957.715946</td>\n",
       "      <td>1524.302375</td>\n",
       "      <td>278.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1992.027309</td>\n",
       "      <td>4266.040908</td>\n",
       "      <td>8082.328949</td>\n",
       "      <td>3654.844534</td>\n",
       "      <td>2982.166900</td>\n",
       "      <td>835.697335</td>\n",
       "      <td>1267.859378</td>\n",
       "      <td>301.174358</td>\n",
       "      <td>2169.396841</td>\n",
       "      <td>2533.194256</td>\n",
       "      <td>521.661900</td>\n",
       "      <td>914.055420</td>\n",
       "      <td>254.425695</td>\n",
       "      <td>1742.283990</td>\n",
       "      <td>12703.270616</td>\n",
       "      <td>2126.924840</td>\n",
       "      <td>23455.534003</td>\n",
       "      <td>2438.488862</td>\n",
       "      <td>766.559807</td>\n",
       "      <td>957.955801</td>\n",
       "      <td>1525.767118</td>\n",
       "      <td>278.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1992.027309</td>\n",
       "      <td>4218.267166</td>\n",
       "      <td>8109.473276</td>\n",
       "      <td>3658.048229</td>\n",
       "      <td>2982.166900</td>\n",
       "      <td>835.698963</td>\n",
       "      <td>1265.143257</td>\n",
       "      <td>302.191081</td>\n",
       "      <td>2169.521447</td>\n",
       "      <td>2532.396849</td>\n",
       "      <td>521.147526</td>\n",
       "      <td>914.055420</td>\n",
       "      <td>254.427690</td>\n",
       "      <td>1739.930269</td>\n",
       "      <td>12703.276471</td>\n",
       "      <td>2124.236647</td>\n",
       "      <td>23470.167258</td>\n",
       "      <td>2438.489002</td>\n",
       "      <td>769.960269</td>\n",
       "      <td>958.035650</td>\n",
       "      <td>1526.999959</td>\n",
       "      <td>278.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1992.027309</td>\n",
       "      <td>4172.652489</td>\n",
       "      <td>8139.089630</td>\n",
       "      <td>3660.889682</td>\n",
       "      <td>2982.166900</td>\n",
       "      <td>835.700420</td>\n",
       "      <td>1262.536676</td>\n",
       "      <td>303.198255</td>\n",
       "      <td>2169.640792</td>\n",
       "      <td>2531.801272</td>\n",
       "      <td>520.791604</td>\n",
       "      <td>914.055420</td>\n",
       "      <td>254.429647</td>\n",
       "      <td>1738.128163</td>\n",
       "      <td>12703.281490</td>\n",
       "      <td>2121.506994</td>\n",
       "      <td>23470.383967</td>\n",
       "      <td>2438.489282</td>\n",
       "      <td>772.862609</td>\n",
       "      <td>957.914135</td>\n",
       "      <td>1527.979339</td>\n",
       "      <td>278.001256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 22 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5084ad7f-2a29-485c-b3db-f1b8a7d07a12')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5084ad7f-2a29-485c-b3db-f1b8a7d07a12 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5084ad7f-2a29-485c-b3db-f1b8a7d07a12');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       ASIANPAINT   BAJFINANCE  ...        TITAN       WIPRO\n",
       "0      850.608887   602.348328  ...   340.842285  202.975677\n",
       "1      852.593201   598.059875  ...   340.212952  203.431641\n",
       "2      871.807617   592.664673  ...   336.630768  203.139801\n",
       "3      858.013977   603.474854  ...   336.776001  202.483200\n",
       "4      844.413879   603.380981  ...   333.096954  200.568176\n",
       "...           ...          ...  ...          ...         ...\n",
       "1309  1992.027309  4359.514840  ...  1522.641586  278.001266\n",
       "1310  1992.027309  4313.668901  ...  1524.302375  278.001256\n",
       "1311  1992.027309  4266.040908  ...  1525.767118  278.001256\n",
       "1312  1992.027309  4218.267166  ...  1526.999959  278.001256\n",
       "1313  1992.027309  4172.652489  ...  1527.979339  278.001256\n",
       "\n",
       "[1314 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata # dataset with 2021 rows forcasted dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "CALvSlILxL35",
    "outputId": "03ec7a3d-abf8-469a-90f7-b7dbbd62eb07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-973f02c1-9707-4ead-ad0f-20e2b55685d6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASIANPAINT</th>\n",
       "      <th>BAJFINANCE</th>\n",
       "      <th>BAJAJFINSV</th>\n",
       "      <th>BRITANNIA</th>\n",
       "      <th>DIVISLAB</th>\n",
       "      <th>HCLTECH</th>\n",
       "      <th>HDFCBANK</th>\n",
       "      <th>HINDALCO</th>\n",
       "      <th>HINDUNILVR</th>\n",
       "      <th>HDFC</th>\n",
       "      <th>ICICIBANK</th>\n",
       "      <th>INFY</th>\n",
       "      <th>JSWSTEEL</th>\n",
       "      <th>KOTAKBANK</th>\n",
       "      <th>NESTLEIND</th>\n",
       "      <th>RELIANCE</th>\n",
       "      <th>SHREECEM</th>\n",
       "      <th>TCS</th>\n",
       "      <th>TATASTEEL</th>\n",
       "      <th>TECHM</th>\n",
       "      <th>TITAN</th>\n",
       "      <th>WIPRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>850.608887</td>\n",
       "      <td>602.348328</td>\n",
       "      <td>1978.543457</td>\n",
       "      <td>1374.428223</td>\n",
       "      <td>1108.503052</td>\n",
       "      <td>385.106506</td>\n",
       "      <td>528.506653</td>\n",
       "      <td>82.550529</td>\n",
       "      <td>792.340698</td>\n",
       "      <td>1169.114624</td>\n",
       "      <td>227.737686</td>\n",
       "      <td>482.005096</td>\n",
       "      <td>93.927940</td>\n",
       "      <td>725.564270</td>\n",
       "      <td>5311.719238</td>\n",
       "      <td>486.556549</td>\n",
       "      <td>11121.029297</td>\n",
       "      <td>1082.013306</td>\n",
       "      <td>219.908173</td>\n",
       "      <td>461.389832</td>\n",
       "      <td>340.842285</td>\n",
       "      <td>202.975677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852.593201</td>\n",
       "      <td>598.059875</td>\n",
       "      <td>1954.307739</td>\n",
       "      <td>1368.077148</td>\n",
       "      <td>1096.297607</td>\n",
       "      <td>385.152100</td>\n",
       "      <td>519.647644</td>\n",
       "      <td>78.515373</td>\n",
       "      <td>794.607056</td>\n",
       "      <td>1130.328369</td>\n",
       "      <td>221.286560</td>\n",
       "      <td>470.513763</td>\n",
       "      <td>95.546753</td>\n",
       "      <td>703.665161</td>\n",
       "      <td>5205.810547</td>\n",
       "      <td>476.948639</td>\n",
       "      <td>10804.255859</td>\n",
       "      <td>1061.057739</td>\n",
       "      <td>219.481003</td>\n",
       "      <td>458.151581</td>\n",
       "      <td>340.212952</td>\n",
       "      <td>203.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>871.807617</td>\n",
       "      <td>592.664673</td>\n",
       "      <td>1940.843384</td>\n",
       "      <td>1365.361816</td>\n",
       "      <td>1094.199951</td>\n",
       "      <td>383.717926</td>\n",
       "      <td>515.715759</td>\n",
       "      <td>80.314178</td>\n",
       "      <td>784.385376</td>\n",
       "      <td>1123.546631</td>\n",
       "      <td>222.282349</td>\n",
       "      <td>468.398560</td>\n",
       "      <td>99.058762</td>\n",
       "      <td>706.109497</td>\n",
       "      <td>5199.016113</td>\n",
       "      <td>481.668732</td>\n",
       "      <td>10867.756836</td>\n",
       "      <td>1051.810791</td>\n",
       "      <td>234.346603</td>\n",
       "      <td>463.031219</td>\n",
       "      <td>336.630768</td>\n",
       "      <td>203.139801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>858.013977</td>\n",
       "      <td>603.474854</td>\n",
       "      <td>1933.413330</td>\n",
       "      <td>1381.469727</td>\n",
       "      <td>1084.378296</td>\n",
       "      <td>383.080475</td>\n",
       "      <td>517.997192</td>\n",
       "      <td>78.320908</td>\n",
       "      <td>779.852783</td>\n",
       "      <td>1123.453613</td>\n",
       "      <td>216.567245</td>\n",
       "      <td>466.348938</td>\n",
       "      <td>96.781441</td>\n",
       "      <td>701.969116</td>\n",
       "      <td>5251.443359</td>\n",
       "      <td>494.631134</td>\n",
       "      <td>11188.242188</td>\n",
       "      <td>1066.431152</td>\n",
       "      <td>229.604980</td>\n",
       "      <td>465.870178</td>\n",
       "      <td>336.776001</td>\n",
       "      <td>202.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>844.413879</td>\n",
       "      <td>603.380981</td>\n",
       "      <td>1921.943726</td>\n",
       "      <td>1356.088257</td>\n",
       "      <td>1074.604370</td>\n",
       "      <td>375.636505</td>\n",
       "      <td>512.706055</td>\n",
       "      <td>74.528839</td>\n",
       "      <td>758.761841</td>\n",
       "      <td>1095.722656</td>\n",
       "      <td>213.666412</td>\n",
       "      <td>458.259216</td>\n",
       "      <td>93.868484</td>\n",
       "      <td>690.046875</td>\n",
       "      <td>5177.484863</td>\n",
       "      <td>485.550232</td>\n",
       "      <td>10725.758789</td>\n",
       "      <td>1061.796509</td>\n",
       "      <td>213.500595</td>\n",
       "      <td>453.183197</td>\n",
       "      <td>333.096954</td>\n",
       "      <td>200.568176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>2557.899902</td>\n",
       "      <td>4736.549805</td>\n",
       "      <td>10001.750000</td>\n",
       "      <td>3526.107910</td>\n",
       "      <td>3784.350098</td>\n",
       "      <td>918.745850</td>\n",
       "      <td>1404.800049</td>\n",
       "      <td>348.350006</td>\n",
       "      <td>2360.649902</td>\n",
       "      <td>2509.800049</td>\n",
       "      <td>591.099976</td>\n",
       "      <td>1343.550049</td>\n",
       "      <td>655.799988</td>\n",
       "      <td>1759.650024</td>\n",
       "      <td>16779.318359</td>\n",
       "      <td>1937.849976</td>\n",
       "      <td>28062.599609</td>\n",
       "      <td>3085.706299</td>\n",
       "      <td>940.750000</td>\n",
       "      <td>962.200012</td>\n",
       "      <td>1479.849976</td>\n",
       "      <td>480.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>2574.350098</td>\n",
       "      <td>4865.049805</td>\n",
       "      <td>10091.349609</td>\n",
       "      <td>3528.100342</td>\n",
       "      <td>3908.949951</td>\n",
       "      <td>918.795288</td>\n",
       "      <td>1438.699951</td>\n",
       "      <td>366.250000</td>\n",
       "      <td>2379.850098</td>\n",
       "      <td>2518.399902</td>\n",
       "      <td>598.750000</td>\n",
       "      <td>1348.500000</td>\n",
       "      <td>665.900024</td>\n",
       "      <td>1750.300049</td>\n",
       "      <td>16688.214844</td>\n",
       "      <td>1988.650024</td>\n",
       "      <td>28098.550781</td>\n",
       "      <td>3116.754150</td>\n",
       "      <td>977.750000</td>\n",
       "      <td>969.250000</td>\n",
       "      <td>1495.099976</td>\n",
       "      <td>485.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2614.550049</td>\n",
       "      <td>5280.899902</td>\n",
       "      <td>10489.299805</td>\n",
       "      <td>3465.881348</td>\n",
       "      <td>3882.600098</td>\n",
       "      <td>913.799988</td>\n",
       "      <td>1476.800049</td>\n",
       "      <td>362.600006</td>\n",
       "      <td>2406.550049</td>\n",
       "      <td>2577.000000</td>\n",
       "      <td>621.349976</td>\n",
       "      <td>1356.000000</td>\n",
       "      <td>662.650024</td>\n",
       "      <td>1811.449951</td>\n",
       "      <td>16543.800781</td>\n",
       "      <td>1997.300049</td>\n",
       "      <td>28687.550781</td>\n",
       "      <td>3108.892822</td>\n",
       "      <td>971.400024</td>\n",
       "      <td>977.400024</td>\n",
       "      <td>1508.849976</td>\n",
       "      <td>489.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2613.449951</td>\n",
       "      <td>5484.850098</td>\n",
       "      <td>11176.549805</td>\n",
       "      <td>3456.067871</td>\n",
       "      <td>3910.850098</td>\n",
       "      <td>909.549988</td>\n",
       "      <td>1472.500000</td>\n",
       "      <td>372.149994</td>\n",
       "      <td>2407.600098</td>\n",
       "      <td>2538.850098</td>\n",
       "      <td>621.450012</td>\n",
       "      <td>1356.349976</td>\n",
       "      <td>726.500000</td>\n",
       "      <td>1805.000000</td>\n",
       "      <td>16502.550781</td>\n",
       "      <td>2024.050049</td>\n",
       "      <td>28444.349609</td>\n",
       "      <td>3100.085693</td>\n",
       "      <td>1031.349976</td>\n",
       "      <td>976.900024</td>\n",
       "      <td>1506.800049</td>\n",
       "      <td>489.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>2536.399902</td>\n",
       "      <td>5451.899902</td>\n",
       "      <td>11041.650391</td>\n",
       "      <td>3436.241455</td>\n",
       "      <td>4062.350098</td>\n",
       "      <td>898.950012</td>\n",
       "      <td>1412.300049</td>\n",
       "      <td>364.399994</td>\n",
       "      <td>2353.750000</td>\n",
       "      <td>2420.100098</td>\n",
       "      <td>600.500000</td>\n",
       "      <td>1354.349976</td>\n",
       "      <td>717.849976</td>\n",
       "      <td>1748.800049</td>\n",
       "      <td>16309.250000</td>\n",
       "      <td>1994.500000</td>\n",
       "      <td>27910.500000</td>\n",
       "      <td>3020.873291</td>\n",
       "      <td>1034.000000</td>\n",
       "      <td>960.400024</td>\n",
       "      <td>1491.650024</td>\n",
       "      <td>492.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1314 rows × 22 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-973f02c1-9707-4ead-ad0f-20e2b55685d6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-973f02c1-9707-4ead-ad0f-20e2b55685d6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-973f02c1-9707-4ead-ad0f-20e2b55685d6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       ASIANPAINT   BAJFINANCE  ...        TITAN       WIPRO\n",
       "0      850.608887   602.348328  ...   340.842285  202.975677\n",
       "1      852.593201   598.059875  ...   340.212952  203.431641\n",
       "2      871.807617   592.664673  ...   336.630768  203.139801\n",
       "3      858.013977   603.474854  ...   336.776001  202.483200\n",
       "4      844.413879   603.380981  ...   333.096954  200.568176\n",
       "...           ...          ...  ...          ...         ...\n",
       "1309  2557.899902  4736.549805  ...  1479.849976  480.299988\n",
       "1310  2574.350098  4865.049805  ...  1495.099976  485.049988\n",
       "1311  2614.550049  5280.899902  ...  1508.849976  489.299988\n",
       "1312  2613.449951  5484.850098  ...  1506.800049  489.850006\n",
       "1313  2536.399902  5451.899902  ...  1491.650024  492.750000\n",
       "\n",
       "[1314 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata # dataset with original 2021 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MNRaqXdcxL36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#fdata.to_csv('data_inc/fdata.csv')   #dataset saved in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7bLAA-IMxL36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#clm=['MSE','RMSE','MAE','R2','MAPE']\n",
    "#pd.DataFrame(mtest,index=stonks,columns=clm).to_csv('data_inc/mtest.csv') #metric values saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xiiuP8SexL37",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(mdynamic,index=stonks,columns=clm).to_csv('data_inc/mdynamic.csv') #metric values saved"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Stacked_LSTM_inc50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
